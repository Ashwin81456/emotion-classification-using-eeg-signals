{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ashwin81456/emotion-classification-using-eeg-signals/blob/main/update.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "pwwbhMy0pssx"
      },
      "outputs": [],
      "source": [
        "#import the required libraries\n",
        "import os\n",
        "import time\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "\n",
        "#for feature extraction\n",
        "from scipy.signal import welch\n",
        "from scipy.integrate import simps\n",
        "\n",
        "#classifier libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "import xgboost as xgb\n",
        "\n",
        "from sklearn import model_selection\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import itertools\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_recall_curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "7ZUAXilSp_n9"
      },
      "outputs": [],
      "source": [
        "def read_data(filename):\n",
        "    x = pickle._Unpickler(open(filename, 'rb'))\n",
        "    x.encoding = 'latin1'\n",
        "    p = x.load()\n",
        "    return p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYK5hgFMqFNy",
        "outputId": "7789d888-c4a0-424a-d414-eea4c755abc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['s01.dat', 's02.dat', 's03.dat', 's04.dat', 's05.dat', 's06.dat', 's07.dat', 's08.dat', 's09.dat', 's10.dat', 's11.dat', 's12.dat', 's13.dat', 's14.dat', 's15.dat', 's16.dat', 's17.dat', 's18.dat', 's19.dat', 's20.dat', 's21.dat', 's22.dat', 's23.dat', 's24.dat', 's25.dat', 's26.dat', 's27.dat', 's28.dat', 's29.dat', 's30.dat', 's31.dat', 's32.dat']\n"
          ]
        }
      ],
      "source": [
        "#creating the file names of the dataset to load it\n",
        "files = []\n",
        "for n in range (1, 33):\n",
        "    s = 's'\n",
        "    if n < 10:\n",
        "        s += '0'\n",
        "    s += str(n)\n",
        "    s+=str(\".dat\")\n",
        "    files.append(s)\n",
        "print(files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ru2cxT3qrtI",
        "outputId": "f20ec4f8-6ee2-4c1b-ec8a-a0b51abfbaff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# 32x40 = 1280 trials for 32 participants\n",
        "labels = []\n",
        "data = []\n",
        "drive.mount('/content/drive')\n",
        "for i in files:\n",
        "  filename = \"/content/drive/My Drive/MajorProject/Dataset/\" + i\n",
        "  trial = read_data(filename)\n",
        "  labels.append(trial['labels'])\n",
        "  data.append(trial['data'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwIUirXzuY_3",
        "outputId": "0224a0d7-3a7e-460b-c686-cd07ebc54924"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels:  (32, 40, 4)\n",
            "Data:  (32, 40, 40, 8064)\n"
          ]
        }
      ],
      "source": [
        "# Lets see the shapes of the raw data\n",
        "labels = np.array(labels)\n",
        "data = np.array(data)\n",
        "print(\"Labels: \", labels.shape) # participants x videos x labels\n",
        "print(\"Data: \", data.shape) # participants x videos x channels x data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "6JhtYReeudzh"
      },
      "outputs": [],
      "source": [
        "# Re-shape arrays into desired shapes\n",
        "labels = labels.flatten()\n",
        "labels = labels.reshape(1280, 4)\n",
        "\n",
        "data = data.flatten()\n",
        "data = data.reshape(1280, 40, 8064)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pw4kk4WasX14",
        "outputId": "9be2040d-bdd1-4f95-b9f7-d82e5c3fa751"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels:  (1280, 4)\n",
            "Data:  (1280, 40, 8064)\n"
          ]
        }
      ],
      "source": [
        "# Double-check the new arrays\n",
        "#Here trial = participants x vidoes = 32 x 40 = 1280\n",
        "\n",
        "print(\"Labels: \", labels.shape) # trial x label\n",
        "print(\"Data: \", data.shape) # trial x channel x data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 630
        },
        "id": "puNQxQcOx0Gq",
        "outputId": "d3a4d191-80a0-477d-acbb-d42f123a8283"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "printing the labels dataframe\n",
            "\n",
            "         0     1     2     3\n",
            "0     7.71  7.60  6.90  7.83\n",
            "1     8.10  7.31  7.28  8.47\n",
            "2     8.58  7.54  9.00  7.08\n",
            "3     4.94  6.01  6.12  8.06\n",
            "4     6.96  3.92  7.19  6.05\n",
            "...    ...   ...   ...   ...\n",
            "1275  3.91  6.96  5.82  3.12\n",
            "1276  2.81  6.13  6.06  1.04\n",
            "1277  3.05  7.01  5.10  1.10\n",
            "1278  3.99  7.17  4.85  1.00\n",
            "1279  7.15  4.03  9.00  1.88\n",
            "\n",
            "[1280 rows x 4 columns]\n",
            "\n",
            "\n",
            "Describing the labels dataframe\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 0            1            2            3\n",
              "count  1280.000000  1280.000000  1280.000000  1280.000000\n",
              "mean      5.254313     5.156711     5.382750     5.518133\n",
              "std       2.130816     2.020499     2.096321     2.282780\n",
              "min       1.000000     1.000000     1.000000     1.000000\n",
              "25%       3.867500     3.762500     3.932500     3.960000\n",
              "50%       5.040000     5.230000     5.240000     6.050000\n",
              "75%       7.050000     6.950000     7.040000     7.090000\n",
              "max       9.000000     9.000000     9.000000     9.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-18f6cf45-c587-4ba7-b6f3-b6dfa19d5d51\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1280.000000</td>\n",
              "      <td>1280.000000</td>\n",
              "      <td>1280.000000</td>\n",
              "      <td>1280.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>5.254313</td>\n",
              "      <td>5.156711</td>\n",
              "      <td>5.382750</td>\n",
              "      <td>5.518133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.130816</td>\n",
              "      <td>2.020499</td>\n",
              "      <td>2.096321</td>\n",
              "      <td>2.282780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>3.867500</td>\n",
              "      <td>3.762500</td>\n",
              "      <td>3.932500</td>\n",
              "      <td>3.960000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5.040000</td>\n",
              "      <td>5.230000</td>\n",
              "      <td>5.240000</td>\n",
              "      <td>6.050000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>7.050000</td>\n",
              "      <td>6.950000</td>\n",
              "      <td>7.040000</td>\n",
              "      <td>7.090000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>9.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>9.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-18f6cf45-c587-4ba7-b6f3-b6dfa19d5d51')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-18f6cf45-c587-4ba7-b6f3-b6dfa19d5d51 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-18f6cf45-c587-4ba7-b6f3-b6dfa19d5d51');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-54ef4eb0-7c50-458a-9dd8-9250ed2bf2ed\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-54ef4eb0-7c50-458a-9dd8-9250ed2bf2ed')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-54ef4eb0-7c50-458a-9dd8-9250ed2bf2ed button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"labelsDf\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 450.87147400594165,\n        \"min\": 1.0,\n        \"max\": 1280.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          5.2543125,\n          5.04,\n          1280.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 450.88279505775586,\n        \"min\": 1.0,\n        \"max\": 1280.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          5.1567109375,\n          5.23,\n          1280.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 2,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 450.85389766830843,\n        \"min\": 1.0,\n        \"max\": 1280.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          5.38275,\n          5.24,\n          1280.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 3,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 450.79289858765816,\n        \"min\": 1.0,\n        \"max\": 1280.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          5.5181328125,\n          6.05,\n          1280.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "#creating the dataframes for the labels\n",
        "labelsDf = pd.DataFrame(labels)\n",
        "print(\"printing the labels dataframe\\n\")\n",
        "print(labelsDf)\n",
        "print(\"\\n\\nDescribing the labels dataframe\")\n",
        "labelsDf.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SGS2ghM3uYC",
        "outputId": "b1be09bb-aa3e-473d-d3b1-db558f5c8478"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 0            1            2            3\n",
            "count  1280.000000  1280.000000  1280.000000  1280.000000\n",
            "mean      5.254313     5.156711     5.382750     5.518133\n",
            "std       2.130816     2.020499     2.096321     2.282780\n",
            "min       1.000000     1.000000     1.000000     1.000000\n",
            "25%       3.867500     3.762500     3.932500     3.960000\n",
            "50%       5.040000     5.230000     5.240000     6.050000\n",
            "75%       7.050000     6.950000     7.040000     7.090000\n",
            "max       9.000000     9.000000     9.000000     9.000000\n"
          ]
        }
      ],
      "source": [
        "#giving names to the label columns\n",
        "df_labels= pd.DataFrame({'valence': labels[:,0], 'arousal': labels[:,1], 'dominance': labels[:,2], 'liking': labels[:,3]})\n",
        "print(labelsDf.describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3boVQ1FE4var",
        "outputId": "e1537b84-013e-4381-905c-38ae199a88c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      valence  arousal\n",
            "0        7.71     7.60\n",
            "1        8.10     7.31\n",
            "2        8.58     7.54\n",
            "3        4.94     6.01\n",
            "4        6.96     3.92\n",
            "...       ...      ...\n",
            "1275     3.91     6.96\n",
            "1276     2.81     6.13\n",
            "1277     3.05     7.01\n",
            "1278     3.99     7.17\n",
            "1279     7.15     4.03\n",
            "\n",
            "[1280 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "#Dropping the Dominance and Liking columns\n",
        "df_labels=df_labels.drop('dominance',axis=1)\n",
        "df_labels=df_labels.drop('liking',axis=1)\n",
        "# print(df_labels.describe())\n",
        "print(df_labels)\n",
        "# df = df.drop('B', axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pet3Pska6SDA"
      },
      "source": [
        "# Separte Valence and Arousal to HAHV, LAHV, HALV, LALV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhIWzOBq6QSq",
        "outputId": "a241c508-7e42-4dd5-a66e-cbd33f68bb72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.23\n",
            "5.04\n",
            "      HAHV  LAHV  HALV  LALV\n",
            "0        1     0     0     0\n",
            "1        1     0     0     0\n",
            "2        1     0     0     0\n",
            "3        0     0     1     0\n",
            "4        0     1     0     0\n",
            "...    ...   ...   ...   ...\n",
            "1275     0     0     1     0\n",
            "1276     0     0     1     0\n",
            "1277     0     0     1     0\n",
            "1278     0     0     1     0\n",
            "1279     0     1     0     0\n",
            "\n",
            "[1280 rows x 4 columns]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# # Create a sample DataFrame with 'valence' and 'arousal' columns\n",
        "# np.random.seed(0)\n",
        "# valence = np.random.uniform(1, 9, 1280)\n",
        "# arousal = np.random.uniform(1, 9, 1280)\n",
        "# data = {'valence': valence, 'arousal': arousal}\n",
        "# df_valence_arousal = pd.DataFrame(data)\n",
        "\n",
        "# Calculate the median value of arousal and valence column\n",
        "arousal_median = df_labels['arousal'].median()\n",
        "print(arousal_median)\n",
        "valence_median = df_labels['valence'].median()\n",
        "print(valence_median)\n",
        "\n",
        "# Create a new DataFrame with the desired columns\n",
        "df_result = pd.DataFrame(index=range(1280), columns=['HAHV', 'LAHV', 'HALV', 'LALV'])\n",
        "df_result[['HAHV', 'LAHV', 'HALV', 'LALV']] = 0\n",
        "\n",
        "# Apply the conditions\n",
        "df_result.loc[(df_labels['valence'] >= valence_median) & (df_labels['arousal'] >= arousal_median), 'HAHV'] = 1\n",
        "df_result.loc[(df_labels['arousal'] < arousal_median) & (df_labels['valence'] >= valence_median), 'LAHV'] = 1\n",
        "df_result.loc[(df_labels['arousal'] >= arousal_median) & (df_labels['valence'] < valence_median), 'HALV'] = 1\n",
        "df_result.loc[(df_labels['valence'] < valence_median) & (df_labels['arousal'] < arousal_median), 'LALV'] = 1\n",
        "\n",
        "# Show the first few rows of the result DataFrame\n",
        "# df_result.tail()\n",
        "print(df_result)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# High Arousal Positive Valence dataset\n",
        "df_hahv = df_labels[(df_labels['valence'] >= np.median(labels[:,0])) & (df_labels['arousal'] >= np.median(labels[:,1]))]\n",
        "# Low Arousal Positive Valence dataset\n",
        "df_lahv = df_labels[(df_labels['valence'] >= np.median(labels[:,0])) & (df_labels['arousal'] < np.median(labels[:,1]))]\n",
        "# High Arousal Negative Valence dataset\n",
        "df_halv = df_labels[(df_labels['valence'] < np.median(labels[:,0])) & (df_labels['arousal'] >= np.median(labels[:,1]))]\n",
        "# Low Arousal Negative Valence dataset\n",
        "df_lalv = df_labels[(df_labels['valence'] < np.median(labels[:,0])) & (df_labels['arousal'] < np.median(labels[:,1]))]"
      ],
      "metadata": {
        "id": "B_fazp2i2KE8"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get mean and std of each group\n",
        "print(\"HAHV\")\n",
        "print(\"Valence:\", \"Mean\", np.round(df_hahv['valence'].mean(),2), \"STD\", np.round(df_hahv['valence'].std(),2))\n",
        "print(\"Arousal:\", \"Mean\", np.round(df_hahv['arousal'].mean(),2), \"STD\", np.round(df_hahv['arousal'].std(),2))\n",
        "print()\n",
        "print(\"LAHV:\")\n",
        "print(\"Valence:\", \"Mean\", np.round(df_lahv['valence'].mean(),2), \"STD\", np.round(df_lahv['valence'].std(),2))\n",
        "print(\"Arousal:\", \"Mean\", np.round(df_lahv['arousal'].mean(),2), \"STD\", np.round(df_lahv['arousal'].std(),2))\n",
        "print()\n",
        "print(\"HALV:\")\n",
        "print(\"Valence:\", \"Mean\", np.round(df_halv['valence'].mean(),2), \"STD\", np.round(df_halv['valence'].std(),2))\n",
        "print(\"Arousal:\", \"Mean\", np.round(df_halv['arousal'].mean(),2), \"STD\", np.round(df_halv['arousal'].std(),2))\n",
        "print()\n",
        "print(\"LALV:\")\n",
        "print(\"Valence:\", \"Mean\", np.round(df_lalv['valence'].mean(),2), \"STD\", np.round(df_lalv['valence'].std(),2))\n",
        "print(\"Arousal:\", \"Mean\", np.round(df_lalv['arousal'].mean(),2), \"STD\", np.round(df_lalv['arousal'].std(),2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yA4yA5xY24qq",
        "outputId": "43731a3c-e065-427b-ee81-a8c6d808c370"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HAHV\n",
            "Valence: Mean 7.23 STD 1.03\n",
            "Arousal: Mean 6.87 STD 0.87\n",
            "\n",
            "LAHV:\n",
            "Valence: Mean 6.59 STD 1.1\n",
            "Arousal: Mean 3.83 STD 1.17\n",
            "\n",
            "HALV:\n",
            "Valence: Mean 3.11 STD 1.25\n",
            "Arousal: Mean 6.8 STD 0.97\n",
            "\n",
            "LALV:\n",
            "Valence: Mean 3.59 STD 1.19\n",
            "Arousal: Mean 3.12 STD 1.32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcYaudZZDylG"
      },
      "source": [
        "Verify the data in 4 classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tc9aAzbD7U3",
        "outputId": "bf72d3f4-ff80-4de9-f3c1-bd3788f2a502"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of 1s in HAHV: 358\n",
            "Number of 1s in LAHV: 322\n",
            "Number of 1s in HALV: 282\n",
            "Number of 1s in LALV: 318\n",
            "Total = 1280\n"
          ]
        }
      ],
      "source": [
        "# Check the number of 1s in each individual column\n",
        "count_HAHV = df_result['HAHV'].sum()\n",
        "count_LAHV = df_result['LAHV'].sum()\n",
        "count_HALV = df_result['HALV'].sum()\n",
        "count_LALV = df_result['LALV'].sum()\n",
        "\n",
        "print(f\"Number of 1s in HAHV: {count_HAHV}\")\n",
        "print(f\"Number of 1s in LAHV: {count_LAHV}\")\n",
        "print(f\"Number of 1s in HALV: {count_HALV}\")\n",
        "print(f\"Number of 1s in LALV: {count_LALV}\")\n",
        "\n",
        "print(f\"Total = {count_HAHV+count_LAHV+count_HALV+count_LALV}\") # the total must be 1280\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#whisker plot of HAHV, LALV, HALV AND LAHV\n",
        "# Valence and Arousal ratings between groups\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(12,4))\n",
        "boxprops = dict(linewidth=2, color='black')\n",
        "whiskerprops = dict(linewidth=2, color='black')\n",
        "capprops = dict(linewidth=2, color='orange')\n",
        "medianprops = dict(linewidth=2, color='red')\n",
        "flierprops = dict(marker='o', color='brown', alpha=0.5)\n",
        "\n",
        "axs[0].set_title(\"Valence\")\n",
        "axs[0].set_ylim(1, 9)\n",
        "axs[0].boxplot([df_hahv['valence'], df_lahv['valence'], df_halv['valence'], df_lalv['valence']], labels=['HAHV','LAHV','HALV', 'LALV'],boxprops=boxprops,\n",
        "               whiskerprops=whiskerprops,\n",
        "               capprops=capprops,\n",
        "               medianprops=medianprops,\n",
        "               flierprops=flierprops)\n",
        "\n",
        "axs[1].set_title(\"Arousal\")\n",
        "axs[1].set_ylim(1, 9)\n",
        "axs[1].boxplot([df_hahv['arousal'], df_lahv['arousal'], df_halv['arousal'], df_lalv['arousal']], labels=['HAHV','LAHV','HALV', 'LALV'],boxprops=boxprops,\n",
        "               whiskerprops=whiskerprops,\n",
        "               capprops=capprops,\n",
        "               medianprops=medianprops,\n",
        "               flierprops=flierprops)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 894
        },
        "id": "HXI6kLgn3PlX",
        "outputId": "17ea60c8-df12-4b42-e0aa-931a327feccc"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'whiskers': [<matplotlib.lines.Line2D at 0x7e9aad8cd360>,\n",
              "  <matplotlib.lines.Line2D at 0x7e9aad8cd600>,\n",
              "  <matplotlib.lines.Line2D at 0x7e9aad8ce5c0>,\n",
              "  <matplotlib.lines.Line2D at 0x7e9aad8ce860>,\n",
              "  <matplotlib.lines.Line2D at 0x7e9aad8cf820>,\n",
              "  <matplotlib.lines.Line2D at 0x7e9aad8cfac0>,\n",
              "  <matplotlib.lines.Line2D at 0x7e9aad90cac0>,\n",
              "  <matplotlib.lines.Line2D at 0x7e9aad90cd60>],\n",
              " 'caps': [<matplotlib.lines.Line2D at 0x7e9aad8cd8a0>,\n",
              "  <matplotlib.lines.Line2D at 0x7e9aad8cdb40>,\n",
              "  <matplotlib.lines.Line2D at 0x7e9aad8ceb00>,\n",
              "  <matplotlib.lines.Line2D at 0x7e9aad8ceda0>,\n",
              "  <matplotlib.lines.Line2D at 0x7e9aad8cfd60>,\n",
              "  <matplotlib.lines.Line2D at 0x7e9aad90c040>,\n",
              "  <matplotlib.lines.Line2D at 0x7e9aad90d000>,\n",
              "  <matplotlib.lines.Line2D at 0x7e9aad90d2a0>],\n",
              " 'boxes': [<matplotlib.lines.Line2D at 0x7e9aad8cd0c0>,\n",
              "  <matplotlib.lines.Line2D at 0x7e9aad8ce320>,\n",
              "  <matplotlib.lines.Line2D at 0x7e9aad8cf580>,\n",
              "  <matplotlib.lines.Line2D at 0x7e9aad90c820>],\n",
              " 'medians': [<matplotlib.lines.Line2D at 0x7e9aad8cdde0>,\n",
              "  <matplotlib.lines.Line2D at 0x7e9aad8cf040>,\n",
              "  <matplotlib.lines.Line2D at 0x7e9aad90c2e0>,\n",
              "  <matplotlib.lines.Line2D at 0x7e9aad90d570>],\n",
              " 'fliers': [<matplotlib.lines.Line2D at 0x7e9aad8ce080>,\n",
              "  <matplotlib.lines.Line2D at 0x7e9aad8cf2e0>,\n",
              "  <matplotlib.lines.Line2D at 0x7e9aad90c580>,\n",
              "  <matplotlib.lines.Line2D at 0x7e9aad90d840>],\n",
              " 'means': []}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Valence and Arousal ratings per group\n",
        "fig, axs = plt.subplots(2, 2, figsize=(12,8))\n",
        "\n",
        "axs[0,0].set_title(\"HAHV\")\n",
        "axs[0,0].set_ylim(1, 9)\n",
        "axs[0,0].boxplot([df_hahv['valence'], df_hahv['arousal']], labels=['Valence','Arousal'],boxprops=boxprops,\n",
        "               whiskerprops=whiskerprops,\n",
        "               capprops=capprops,\n",
        "               medianprops=medianprops,\n",
        "               flierprops=flierprops)\n",
        "\n",
        "axs[0,1].set_title(\"LAHV\")\n",
        "axs[0,1].set_ylim(1, 9)\n",
        "axs[0,1].boxplot([df_lahv['valence'], df_lahv['arousal']], labels=['Valence','Arousal'],boxprops=boxprops,\n",
        "               whiskerprops=whiskerprops,\n",
        "               capprops=capprops,\n",
        "               medianprops=medianprops,\n",
        "               flierprops=flierprops)\n",
        "\n",
        "axs[1,0].set_title(\"HALV\")\n",
        "axs[1,0].set_ylim(1, 9)\n",
        "axs[1,0].boxplot([df_halv['valence'], df_halv['arousal']], labels=['Valence','Arousal'],boxprops=boxprops,\n",
        "               whiskerprops=whiskerprops,\n",
        "               capprops=capprops,\n",
        "               medianprops=medianprops,\n",
        "               flierprops=flierprops)\n",
        "\n",
        "axs[1,1].set_title(\"LALV\")\n",
        "axs[1,1].set_ylim(1, 9)\n",
        "axs[1,1].boxplot([df_lalv['valence'], df_lalv['arousal']], labels=['Valence','Arousal'],boxprops=boxprops,\n",
        "               whiskerprops=whiskerprops,\n",
        "               capprops=capprops,\n",
        "               medianprops=medianprops,\n",
        "               flierprops=flierprops)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 959
        },
        "id": "ZW2mrFGi5M54",
        "outputId": "5f44eb31-3d72-4799-ec1e-0e83cdbe265e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'whiskers': [<matplotlib.lines.Line2D at 0x7e9aadb61a50>,\n",
              "  <matplotlib.lines.Line2D at 0x7e9aadb610c0>,\n",
              "  <matplotlib.lines.Line2D at 0x7e9aada54640>,\n",
              "  <matplotlib.lines.Line2D at 0x7e9aada550f0>],\n",
              " 'caps': [<matplotlib.lines.Line2D at 0x7e9aada817b0>,\n",
              "  <matplotlib.lines.Line2D at 0x7e9aada81510>,\n",
              "  <matplotlib.lines.Line2D at 0x7e9aada56a40>,\n",
              "  <matplotlib.lines.Line2D at 0x7e9aada57490>],\n",
              " 'boxes': [<matplotlib.lines.Line2D at 0x7e9aadb612a0>,\n",
              "  <matplotlib.lines.Line2D at 0x7e9aada83d30>],\n",
              " 'medians': [<matplotlib.lines.Line2D at 0x7e9aada82860>,\n",
              "  <matplotlib.lines.Line2D at 0x7e9aada57ee0>],\n",
              " 'fliers': [<matplotlib.lines.Line2D at 0x7e9aada832e0>,\n",
              "  <matplotlib.lines.Line2D at 0x7e9aada55c00>],\n",
              " 'means': []}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Pjhzu_pQlWDv"
      },
      "outputs": [],
      "source": [
        "# Dataset with only Valence column\n",
        "df_val = df_labels['valence']\n",
        "# Dataset with only Arousal column\n",
        "df_aro = df_labels['arousal']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "u8H4KOWLll-C"
      },
      "outputs": [],
      "source": [
        "# Function to check if each trial has positive or negative valence\n",
        "def positive_valence(trial):\n",
        "    return 1 if labels[trial,0] >= np.median(labels[:,0]) else 0\n",
        "# Function to check if each trial has high or low arousal\n",
        "def high_arousal(trial):\n",
        "    return 1 if labels[trial,1] >= np.median(labels[:,1]) else 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37Gsz-Z_lp_2",
        "outputId": "fb186c99-ec2d-4f2f-b7a8-4405157de196"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       High Valence  High Arousal\n",
            "count   1280.000000   1280.000000\n",
            "mean       0.531250      0.500000\n",
            "std        0.499218      0.500195\n",
            "min        0.000000      0.000000\n",
            "25%        0.000000      0.000000\n",
            "50%        1.000000      0.500000\n",
            "75%        1.000000      1.000000\n",
            "max        1.000000      1.000000\n",
            "      High Valence  High Arousal\n",
            "0                1             1\n",
            "1                1             1\n",
            "2                1             1\n",
            "3                0             1\n",
            "4                1             0\n",
            "...            ...           ...\n",
            "1275             0             1\n",
            "1276             0             1\n",
            "1277             0             1\n",
            "1278             0             1\n",
            "1279             1             0\n",
            "\n",
            "[1280 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "# Convert all ratings to boolean values\n",
        "labels_encoded = []\n",
        "for i in range (len(labels)):\n",
        "    labels_encoded.append([positive_valence(i), high_arousal(i)])\n",
        "labels_encoded = np.reshape(labels_encoded, (1280, 2))\n",
        "df_labels = pd.DataFrame(data=labels_encoded, columns=[\"High Valence\", \"High Arousal\"])\n",
        "print(df_labels.describe())\n",
        "print(df_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BrMAjqult5R",
        "outputId": "53f24d00-02a1-4d71-c668-28800283bd60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0       1\n",
            "1       1\n",
            "2       1\n",
            "3       0\n",
            "4       1\n",
            "       ..\n",
            "1275    0\n",
            "1276    0\n",
            "1277    0\n",
            "1278    0\n",
            "1279    1\n",
            "Name: High Valence, Length: 1280, dtype: int64\n",
            "(1280,)\n"
          ]
        }
      ],
      "source": [
        "# Dataset with only Valence column\n",
        "df_valence = df_labels['High Valence']\n",
        "# Dataset with only Arousal column\n",
        "df_arousal = df_labels['High Arousal']\n",
        "print(df_valence)\n",
        "print(df_valence.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gh0IevZcnKtX"
      },
      "source": [
        "# FEATURE EXTRACTION USING WELCH'S METHOD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "QGtC7nRipvA8"
      },
      "outputs": [],
      "source": [
        "eeg_channels = np.array([\"Fp1\", \"AF3\", \"F3\", \"F7\", \"FC5\", \"FC1\", \"C3\", \"T7\", \"CP5\", \"CP1\", \"P3\", \"P7\", \"PO3\", \"O1\", \"Oz\", \"Pz\", \"Fp2\", \"AF4\", \"Fz\", \"F4\", \"F8\", \"FC6\", \"FC2\", \"Cz\", \"C4\", \"T8\", \"CP6\", \"CP2\", \"P4\", \"P8\", \"PO4\", \"O2\"])\n",
        "peripheral_channels = np.array([\"hEOG\", \"vEOG\", \"zEMG\", \"tEMG\", \"GSR\", \"Respiration belt\", \"Plethysmograph\", \"Temperature\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyC_7IWLp93t",
        "outputId": "cc1537dc-9fa7-4288-83f8-0d9629caf852"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1280, 32, 8064)\n"
          ]
        }
      ],
      "source": [
        "eeg_data = []\n",
        "for i in range (len(data)):\n",
        "  for j in range (len(eeg_channels)):\n",
        "    eeg_data.append(data[i,j])\n",
        "eeg_data = np.reshape(eeg_data, (len(data), len(eeg_channels), len(data[0,0])))\n",
        "print(eeg_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5P3G0PWqEsM",
        "outputId": "d563b058-1678-4b46-cb08-72a1ae83c24e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1280, 8, 8064)\n"
          ]
        }
      ],
      "source": [
        "peripheral_data = []\n",
        "for i in range (len(data)):\n",
        "  for j in range (32,len(data[0])):\n",
        "    peripheral_data.append(data[i,j])\n",
        "peripheral_data = np.reshape(peripheral_data, (len(data), len(peripheral_channels), len(data[0,0])))\n",
        "print(peripheral_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xc9rTRGHnYKt"
      },
      "outputs": [],
      "source": [
        "def bandpower(data, sf, band, window_sec=None, relative=False):\n",
        "    band = np.asarray(band)\n",
        "    low, high = band\n",
        "\n",
        "    # Define window length\n",
        "    if window_sec is not None:\n",
        "        nperseg = window_sec * sf\n",
        "    else:\n",
        "        nperseg = (2 / low) * sf\n",
        "\n",
        "    # Compute the modified periodogram (Welch)\n",
        "    freqs, psd = welch(data, sf, nperseg=nperseg)\n",
        "\n",
        "    # Frequency resolution\n",
        "    freq_res = freqs[1] - freqs[0]\n",
        "\n",
        "    # Find closest indices of band in frequency vector\n",
        "    idx_band = np.logical_and(freqs >= low, freqs <= high)\n",
        "\n",
        "    # Integral approximation of the spectrum using Simpson's rule.\n",
        "    bp = simps(psd[idx_band], dx=freq_res)\n",
        "\n",
        "    if relative:\n",
        "        bp /= simps(psd, dx=freq_res)\n",
        "    return bp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mIxttAuQnrel"
      },
      "outputs": [],
      "source": [
        "def get_band_power(trial, channel, band):\n",
        "  bd = (0,0)\n",
        "\n",
        "  if (band == \"theta\"): # drownsiness, emotional connection, intuition, creativity\n",
        "    bd = (4,8)\n",
        "  elif (band == \"alpha\"): # reflection, relaxation\n",
        "    bd = (8,12)\n",
        "  elif (band == \"beta\"): # concentration, problem solving, memory\n",
        "    bd = (12,30)\n",
        "  elif (band == \"gamma\"): # cognition, perception, learning, multi-tasking\n",
        "    bd = (30,64)\n",
        "\n",
        "  return bandpower(eeg_data[trial,channel], 128, bd)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpNyS4s8n9Q3",
        "outputId": "9eccf45f-e01c-4f7d-b8a3-ed947ba28188"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.434119660168186\n",
            "5.369595513295193\n",
            "6.286556266834863\n",
            "0.9879159580139809\n"
          ]
        }
      ],
      "source": [
        "print(get_band_power(0,31,\"theta\"))\n",
        "print(get_band_power(0,31,\"alpha\"))\n",
        "print(get_band_power(0,31,\"beta\"))\n",
        "print(get_band_power(0,31,\"gamma\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8psQHMB9xqpj"
      },
      "source": [
        "# Process new datasets with 6 EEG regions and 4 band power values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0y_hNHIxoxi"
      },
      "outputs": [],
      "source": [
        "# Transform 1280x 32 x 8064 => 1280 x 128\n",
        "eeg_band_arr = []\n",
        "for i in range (len(eeg_data)):\n",
        "  for j in range (len(eeg_data[0])):\n",
        "    eeg_band_arr.append(get_band_power(i,j,\"theta\"))\n",
        "    eeg_band_arr.append(get_band_power(i,j,\"alpha\"))\n",
        "    eeg_band_arr.append(get_band_power(i,j,\"beta\"))\n",
        "    eeg_band_arr.append(get_band_power(i,j,\"gamma\"))\n",
        "eeg_band_arr = np.reshape(eeg_band_arr, (1280, 128))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVksA4V2ypUD"
      },
      "outputs": [],
      "source": [
        "frontal = np.array([\"F3\", \"FC1\", \"Fz\", \"F4\", \"FC2\"])\n",
        "parietal = np.array([\"P3\", \"P7\", \"Pz\", \"P4\", \"P8\"])\n",
        "occipital = np.array([\"O1\", \"Oz\", \"O2\", \"PO3\", \"PO4\"])\n",
        "central = np.array([\"CP5\", \"CP1\", \"Cz\", \"C4\", \"C3\", \"CP6\", \"CP2\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YQbtKTRzmdG",
        "outputId": "f627f7a9-6457-4201-9af0-397af79b7023"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                Fp1           AF3            F3            F7           FC5  \\\n",
            "count   1280.000000   1280.000000   1280.000000   1280.000000   1280.000000   \n",
            "mean     517.431002    974.493856    795.093910   1515.004071    746.435950   \n",
            "std     1165.295163   3147.555132   3020.711666   4990.544508   2188.101734   \n",
            "min        2.698928      1.995398      1.820656      3.283107      1.311200   \n",
            "25%       23.306027     17.117475     18.392335     30.827191     14.023436   \n",
            "50%       65.468048     82.102529     60.241953     91.266539     48.704968   \n",
            "75%      331.636624    304.949248    175.394835    248.308696    218.358248   \n",
            "max    15524.135098  38122.870846  39431.320394  49272.793208  20182.668545   \n",
            "\n",
            "               FC1            C3           T7           CP5          CP1  ...  \\\n",
            "count  1280.000000   1280.000000  1280.000000   1280.000000  1280.000000  ...   \n",
            "mean    345.936665    486.095113   354.004358    664.656754   276.667812  ...   \n",
            "std     717.328768   1497.636647   641.432373   2146.857585   498.823733  ...   \n",
            "min       2.025214      1.200156     3.418167      1.857737     1.340340  ...   \n",
            "25%      17.383454     18.273844    43.838157     19.178089    28.281757  ...   \n",
            "50%      55.561232     46.451432   128.629588     61.998792    60.330974  ...   \n",
            "75%     281.828747    234.342275   348.249862    312.653366   237.040645  ...   \n",
            "max    8542.244175  26021.167025  7023.985761  23255.512271  5972.589469  ...   \n",
            "\n",
            "                FC2            Cz            C4            T8           CP6  \\\n",
            "count   1280.000000   1280.000000   1280.000000   1280.000000   1280.000000   \n",
            "mean     669.953166    518.975872    471.905917    763.990397    544.785103   \n",
            "std     1714.340609   1407.210210   1896.584105   2236.655420   1563.878765   \n",
            "min        2.809501      1.637028      1.713283      2.133474      1.496299   \n",
            "25%       14.927239     23.440039      9.724978     25.143155     18.202863   \n",
            "50%       66.078472     67.044674     24.318235     90.110040     77.517763   \n",
            "75%      214.293557    305.766182    109.715681    386.232875    297.742897   \n",
            "max    18617.218099  16408.471958  24826.365142  28038.714329  19908.437378   \n",
            "\n",
            "               CP2            P4           P8           PO4            O2  \n",
            "count  1280.000000   1280.000000  1280.000000   1280.000000   1280.000000  \n",
            "mean    303.158814    527.491149   222.759444    780.700914    327.242856  \n",
            "std     650.093432   1429.084909   451.119818   1802.083002   1080.707954  \n",
            "min       1.439077      1.791296     1.641482      1.995230      3.681268  \n",
            "25%      26.754006     18.110041    18.064264     23.491991     19.333926  \n",
            "50%      88.083088     62.269206    90.914662     69.772647     49.630345  \n",
            "75%     257.959593    246.195582   225.463786    495.202699    113.117403  \n",
            "max    7210.746793  17568.065100  5487.311705  17167.017710  12314.030522  \n",
            "\n",
            "[8 rows x 32 columns]\n"
          ]
        }
      ],
      "source": [
        "eeg_theta = []\n",
        "for i in range (len(eeg_data)):\n",
        "  for j in range (len(eeg_data[0])):\n",
        "    eeg_theta.append(get_band_power(i,j,\"theta\"))\n",
        "eeg_theta = np.reshape(eeg_theta, (1280, 32))\n",
        "\n",
        "df_theta = pd.DataFrame(data = eeg_theta, columns=eeg_channels)\n",
        "print(df_theta.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1uT6ZlnzqL-",
        "outputId": "6027237f-1bc1-41c5-94f4-0bd96c53ef1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               Fp1           AF3            F3            F7          FC5  \\\n",
            "count  1280.000000   1280.000000   1280.000000   1280.000000  1280.000000   \n",
            "mean    173.544174    333.184883    285.545436    573.725974   249.793720   \n",
            "std     378.371554   1058.758333   1036.330438   1943.692827   702.436934   \n",
            "min       2.770151      1.793012      1.724442      2.793554     0.975527   \n",
            "25%      14.082681     10.737435     10.012318     15.888935    10.074042   \n",
            "50%      33.713172     34.992442     30.026795     38.178299    20.079100   \n",
            "75%     125.508396    114.334883     73.488279     93.987498    74.040939   \n",
            "max    5627.906982  12380.702125  12764.724842  20843.070851  6575.781434   \n",
            "\n",
            "               FC1           C3           T7          CP5          CP1  ...  \\\n",
            "count  1280.000000  1280.000000  1280.000000  1280.000000  1280.000000  ...   \n",
            "mean    138.011594   170.423962   124.101183   232.750895    97.610644  ...   \n",
            "std     275.218934   497.507620   200.171342   735.717912   166.430024  ...   \n",
            "min       1.682977     1.963403     2.545447     2.251935     1.682386  ...   \n",
            "25%       9.228670    10.197058    21.452775    11.461012    13.367379  ...   \n",
            "50%      24.929907    22.318468    51.473641    25.364340    26.229818  ...   \n",
            "75%     117.988147    83.518174   129.890552   110.822931    91.941255  ...   \n",
            "max    3030.077791  9215.549575  2142.437275  7894.273428  2148.109415  ...   \n",
            "\n",
            "               FC2           Cz            C4           T8          CP6  \\\n",
            "count  1280.000000  1280.000000   1280.000000  1280.000000  1280.000000   \n",
            "mean    228.331178   199.941306    193.380344   276.638039   213.620700   \n",
            "std     569.202821   578.947819    812.031964   782.782127   661.135030   \n",
            "min       2.390011     1.315395      1.227024     1.636114     2.181082   \n",
            "25%       8.715210    12.127290      6.665166    15.980086    11.300805   \n",
            "50%      26.880000    29.827367     14.169702    34.252038    31.722499   \n",
            "75%      95.964685   102.480314     40.800135   142.704220   106.673844   \n",
            "max    6038.451512  6881.486185  10501.570698  9022.269308  8394.200372   \n",
            "\n",
            "               CP2           P4           P8          PO4           O2  \n",
            "count  1280.000000  1280.000000  1280.000000  1280.000000  1280.000000  \n",
            "mean    112.138023   181.507936    89.003586   269.572920   126.053116  \n",
            "std     236.260122   482.163785   186.841170   597.330120   400.465505  \n",
            "min       1.520363     2.158950     1.212432     2.002769     3.617116  \n",
            "25%      15.797490    11.564300    10.971965    13.489443    10.548845  \n",
            "50%      37.807211    28.494994    38.758864    29.247807    23.906708  \n",
            "75%      86.070815    92.261617    88.107272   162.117585    45.294454  \n",
            "max    2368.537880  5666.733316  2323.499853  5542.263376  3966.714864  \n",
            "\n",
            "[8 rows x 32 columns]\n"
          ]
        }
      ],
      "source": [
        "# Transform 880 x 32 x 8064 => 880 x 32\n",
        "eeg_alpha = []\n",
        "for i in range (len(eeg_data)):\n",
        "  for j in range (len(eeg_data[0])):\n",
        "    eeg_alpha.append(get_band_power(i,j,\"alpha\"))\n",
        "eeg_alpha = np.reshape(eeg_alpha, (1280, 32))\n",
        "\n",
        "df_alpha = pd.DataFrame(data = eeg_alpha, columns=eeg_channels)\n",
        "print(df_alpha.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUNGxdRLzvAW",
        "outputId": "836e7504-40b3-4382-860a-eb28db8c9e0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               Fp1          AF3           F3            F7          FC5  \\\n",
            "count  1280.000000  1280.000000  1280.000000   1280.000000  1280.000000   \n",
            "mean     92.200266   200.684361   193.372441    341.951096   140.642394   \n",
            "std     176.162562   668.027842   668.771074   1274.679748   386.740178   \n",
            "min       4.486703     2.650970     2.784376      3.363422     2.788531   \n",
            "25%      17.999409    13.190613    10.170223     17.951892    11.341571   \n",
            "50%      34.413828    29.155242    28.120517     33.617573    22.402198   \n",
            "75%      80.774739   107.619088    59.807546     62.087123    53.162211   \n",
            "max    3528.485435  5784.160193  5841.475721  14848.700463  3094.687504   \n",
            "\n",
            "               FC1           C3           T7          CP5          CP1  ...  \\\n",
            "count  1280.000000  1280.000000  1280.000000  1280.000000  1280.000000  ...   \n",
            "mean     99.397187    96.901859    77.540922   137.387625    55.047411  ...   \n",
            "std     197.556641   247.621839    90.107877   409.366974    85.846400  ...   \n",
            "min       3.145262     2.991550     2.477519     2.886994     2.237445  ...   \n",
            "25%       8.919796     9.331138    23.668656    11.097811     9.370318  ...   \n",
            "50%      17.625226    19.698019    44.350493    22.622621    18.748879  ...   \n",
            "75%      79.066898    46.494215    93.087474    58.273844    51.308093  ...   \n",
            "max    1702.542675  5187.441594   634.645675  4094.116788  1238.024108  ...   \n",
            "\n",
            "               FC2           Cz           C4           T8          CP6  \\\n",
            "count  1280.000000  1280.000000  1280.000000  1280.000000  1280.000000   \n",
            "mean    130.756212   131.961699   136.536661   178.534190   144.021213   \n",
            "std     338.843374   409.481195   603.902680   506.405387   484.806320   \n",
            "min       3.037555     1.816169     2.079646     2.429178     2.524762   \n",
            "25%       9.115906    10.803851     7.350435    17.466794    11.400277   \n",
            "50%      17.479204    25.300435    12.926731    30.157902    23.679679   \n",
            "75%      75.259937    54.745901    25.609433    93.320360    64.338413   \n",
            "max    2786.622358  4842.537927  7489.480637  4064.418656  5955.637009   \n",
            "\n",
            "               CP2           P4           P8          PO4           O2  \n",
            "count  1280.000000  1280.000000  1280.000000  1280.000000  1280.000000  \n",
            "mean     74.751315   103.971557    62.850280   148.868580    90.837375  \n",
            "std     165.803855   288.941591   134.177873   329.650542   275.150372  \n",
            "min       2.272088     2.914214     3.059450     2.461123     5.084168  \n",
            "25%      13.014515    11.560334    12.312069    13.732279    11.291516  \n",
            "50%      24.705624    20.439224    27.763129    23.940855    19.688820  \n",
            "75%      53.062550    67.593128    64.187473    99.947093    36.076683  \n",
            "max    1265.234960  2533.794744  1653.743590  2516.334382  2454.759737  \n",
            "\n",
            "[8 rows x 32 columns]\n"
          ]
        }
      ],
      "source": [
        "# Transform 880 x 32 x 8064 => 880 x 32\n",
        "eeg_beta = []\n",
        "for i in range (len(eeg_data)):\n",
        "  for j in range (len(eeg_data[0])):\n",
        "    eeg_beta.append(get_band_power(i,j,\"beta\"))\n",
        "eeg_beta = np.reshape(eeg_beta, (1280, 32))\n",
        "\n",
        "df_beta = pd.DataFrame(data = eeg_beta, columns=eeg_channels)\n",
        "print(df_beta.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJP58i-60AEV",
        "outputId": "4e551a91-ced0-420c-ca45-5e40b606fc96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               Fp1          AF3           F3           F7          FC5  \\\n",
            "count  1280.000000  1280.000000  1280.000000  1280.000000  1280.000000   \n",
            "mean     50.663247   150.492372   149.210824   122.775294    91.633571   \n",
            "std     135.591365   645.635199   632.049548   496.744509   340.562025   \n",
            "min       1.069233     1.119910     0.791859     1.177512     0.712624   \n",
            "25%       8.292302     5.605668     4.352724     7.591098     5.172920   \n",
            "50%      18.329100    14.069330    11.828027    15.919877    12.648067   \n",
            "75%      39.995543    43.454610    28.586812    36.456420    38.094737   \n",
            "max    3213.255538  6060.539788  5758.756812  6348.177208  3472.515858   \n",
            "\n",
            "               FC1           C3           T7          CP5          CP1  ...  \\\n",
            "count  1280.000000  1280.000000  1280.000000  1280.000000  1280.000000  ...   \n",
            "mean     60.487715    56.236468    43.792285    77.048369    29.250057  ...   \n",
            "std     139.230040   180.285647    62.089299   267.809883    68.503827  ...   \n",
            "min       0.694928     0.684210     0.562676     0.788359     0.509259  ...   \n",
            "25%       2.666459     3.534375    10.492723     3.837095     3.156311  ...   \n",
            "50%       5.313502     9.056340    23.540152     9.532963     7.735783  ...   \n",
            "75%      41.027482    29.838450    54.382720    22.302862    18.604669  ...   \n",
            "max    1413.985901  4376.356658   809.935644  2294.561961  1011.985310  ...   \n",
            "\n",
            "               FC2           Cz           C4           T8          CP6  \\\n",
            "count  1280.000000  1280.000000  1280.000000  1280.000000  1280.000000   \n",
            "mean     79.191679    56.547283    55.989289   117.745424    64.340498   \n",
            "std     306.464243   167.968314   239.143748   428.381018   199.387966   \n",
            "min       0.692350     0.395680     0.697486     1.027260     0.609425   \n",
            "25%       2.893590     3.800780     2.286229     7.221083     3.850387   \n",
            "50%       7.535055     8.493068     4.640151    17.921722    10.563661   \n",
            "75%      26.896601    20.882885    13.538524    39.981006    30.943717   \n",
            "max    2829.052404  1892.813293  3054.309237  3954.519861  2405.614840   \n",
            "\n",
            "               CP2           P4           P8          PO4           O2  \n",
            "count  1280.000000  1280.000000  1280.000000  1280.000000  1280.000000  \n",
            "mean     46.943309    68.100629    29.805883    82.197819    55.821892  \n",
            "std     142.501802   265.168885    57.843154   272.880509   203.288109  \n",
            "min       0.478152     0.761387     0.804002     0.838747     0.877576  \n",
            "25%       3.849956     3.690054     4.513405     4.620006     4.380690  \n",
            "50%       8.646393     7.300040    10.911662    10.430337     6.994829  \n",
            "75%      22.614200    28.908609    26.489674    42.960182    14.567389  \n",
            "max    1426.462453  2446.765512   647.533599  2505.826127  1794.801694  \n",
            "\n",
            "[8 rows x 32 columns]\n"
          ]
        }
      ],
      "source": [
        "# Transform 880 x 32 x 8064 => 880 x 32\n",
        "eeg_gamma = []\n",
        "for i in range (len(eeg_data)):\n",
        "  for j in range (len(eeg_data[0])):\n",
        "    eeg_gamma.append(get_band_power(i,j,\"gamma\"))\n",
        "eeg_gamma = np.reshape(eeg_gamma, (1280, 32))\n",
        "\n",
        "df_gamma = pd.DataFrame(data = eeg_gamma, columns=eeg_channels)\n",
        "print(df_gamma.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kmTpi6Qc02Bu"
      },
      "outputs": [],
      "source": [
        "# Split the data into training/testing sets\n",
        "def split_train_test(x, y):\n",
        "  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=42)\n",
        "  return x_train, x_test, y_train, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cOCvaWDba3pa"
      },
      "outputs": [],
      "source": [
        "# Feature scaling\n",
        "def feature_scaling(train, test):\n",
        "  sc = StandardScaler()\n",
        "  train = sc.fit_transform(train)\n",
        "  test = sc.transform(test)\n",
        "  return train, test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHrmKN1nf8ys"
      },
      "outputs": [],
      "source": [
        "band_names = np.array([\"theta\", \"alpha\", \"beta\", \"gamma\"])\n",
        "channel_names = np.array([\"frontal\",  \"central\", \"parietal\", \"occipital\"])\n",
        "label_names = np.array([\"valence\", \"arousal\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYVZwPvFgATk"
      },
      "outputs": [],
      "source": [
        "# Testing different kernels (linear, sigmoid, rbf, poly) to select the most optimal one\n",
        "clf_svm = SVC(kernel = 'rbf',random_state = 42, probability=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4pznSOZgHmK"
      },
      "outputs": [],
      "source": [
        "# Testing different k (odd) numbers, algorithm (auto, ball_tree, kd_tree) and weight (uniform, distance) to select the most optimal one\n",
        "clf_knn = KNeighborsClassifier(n_neighbors=5, weights='distance', algorithm='auto')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7gi_aMFOgL08"
      },
      "outputs": [],
      "source": [
        "clf_dtree=DecisionTreeClassifier(max_depth=20,min_samples_split=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9hH4fktgPOX"
      },
      "outputs": [],
      "source": [
        "clf_rf=RandomForestClassifier(n_estimators=50,max_depth=20,min_samples_split=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7lJ9wwn0gUmH"
      },
      "outputs": [],
      "source": [
        "clf_nb= GaussianNB()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-f5ay_0gYey"
      },
      "outputs": [],
      "source": [
        "# Testing different learning rate (alpha), solver (adam, sgd, lbfgs) and activation (relu, tanh, logistic) to select the most optimal one\n",
        "clf_mlp = MLPClassifier(solver='adam', activation='tanh', alpha=0.3, max_iter=400)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOCq_XttoT4e"
      },
      "outputs": [],
      "source": [
        "clf_adaboost = AdaBoostClassifier(n_estimators=50, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJMuk2lWq8v6"
      },
      "outputs": [],
      "source": [
        "clf_xgb = xgb.XGBClassifier(learning_rate=0.1, max_depth=3, n_estimators=100, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KFc0oT1XMHGv"
      },
      "outputs": [],
      "source": [
        "import lightgbm as lgb\n",
        "clf_lgbm = lgb.LGBMClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_SB4HCTNIWQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "clf_gpc = GaussianProcessClassifier(kernel=1.0 * RBF(length_scale=1.0), random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQ_4Dt-2N5t8"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import Perceptron\n",
        "clf_perceptron = Perceptron(random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pheOwL8PlYt",
        "outputId": "31aba06f-3fcd-47a5-bba3-6c44ee09ca32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.5-cp310-cp310-manylinux2014_x86_64.whl (98.2 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m98.2/98.2 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.25.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.0.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.11.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.3.0)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.2.5\n"
          ]
        }
      ],
      "source": [
        "!pip install catboost\n",
        "import catboost as cb\n",
        "clf_catboost = cb.CatBoostClassifier(iterations=1000, depth=6, learning_rate=0.1, loss_function='Logloss', verbose=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#define cnn model\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Input\n",
        "\n",
        "def create_cnn_model(data_np):\n",
        "    model = Sequential([\n",
        "        Input(shape=(data_np.shape[1], 1)),  # Adjusted to match data_np shape\n",
        "        Conv1D(filters=64, kernel_size=1, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Dropout(0.2),\n",
        "        Conv1D(filters=64, kernel_size=1, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Dropout(0.2),\n",
        "        Flatten(),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.1),\n",
        "        Dense(2, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def train_and_evaluate_cnn(df_x, df_y):\n",
        "    # Convert dataframes to numpy arrays\n",
        "    data_np = df_x.values\n",
        "    labels_np = df_y.values\n",
        "\n",
        "    # Reshape data for CNN: (number of samples, height, width, channels)\n",
        "    # Here, height=1, width=number of features, channels=1\n",
        "    data_reshaped = data_np.reshape((data_np.shape[0], data_np.shape[1], 1))\n",
        "\n",
        "    # One-hot encode the labels\n",
        "    labels_encoded = to_categorical(labels_np)\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(data_reshaped, labels_encoded, test_size=0.20, random_state=42)\n",
        "\n",
        "    # Define the CNN model\n",
        "    model = create_cnn_model(data_np)\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "\n",
        "    return test_loss, test_accuracy\n"
      ],
      "metadata": {
        "id": "tIwd_l6MD6dw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define ann model\n",
        "def create_ann_model(data_scaled):\n",
        "    model = Sequential([\n",
        "        Dense(64, input_dim=data_scaled.shape[1], activation='relu'),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(2, activation='softmax')  # Assuming two classes: 0 and 1\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "\n",
        "def train_and_evaluate_ann(df_x, df_y):\n",
        "    # Convert dataframes to numpy arrays\n",
        "    data_np = df_x.values\n",
        "    labels_np = df_y.values\n",
        "\n",
        "    # Standardize the data\n",
        "    scaler = StandardScaler()\n",
        "    data_scaled = scaler.fit_transform(data_np)\n",
        "\n",
        "    # One-hot encode the labels\n",
        "    labels_encoded = to_categorical(labels_np)\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(data_scaled, labels_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Define the CNN model\n",
        "    model = create_ann_model(data_np)\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "\n",
        "    return test_loss, test_accuracy"
      ],
      "metadata": {
        "id": "C81EuQgrZIim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define lstm model\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "def create_lstm_model(data_np):\n",
        "    model = Sequential([\n",
        "    LSTM(20, input_shape=(data_np.shape[1], 1)),\n",
        "    Dropout(0.5),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(2, activation='softmax')  # Assuming two classes: 0 and 1\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def train_and_evaluate_lstm(df_x, df_y):\n",
        "    # Convert dataframes to numpy arrays\n",
        "    data_np = df_x.values\n",
        "    labels_np = df_y.values\n",
        "\n",
        "    # Reshape data for LSTM: (samples, time_steps, features)\n",
        "    # Here, each row is treated as a sequence with a single time step\n",
        "    data_reshaped = data_np.reshape((data_np.shape[0], data_np.shape[1], 1))\n",
        "\n",
        "    # One-hot encode the labels\n",
        "    labels_encoded = to_categorical(labels_np)\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(data_reshaped, labels_encoded, test_size=0.2, random_state=42)\n",
        "    # Define the CNN model\n",
        "    model = create_lstm_model(data_np)\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "    return test_loss, test_accuracy\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7hC14PKCbZUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i28DLITPgfgJ"
      },
      "outputs": [],
      "source": [
        "models = []\n",
        "models.append(('SVM', clf_svm))\n",
        "models.append(('k-NN', clf_knn))\n",
        "models.append(('DT', clf_dtree))\n",
        "models.append(('RF', clf_rf))\n",
        "models.append(('NB', clf_nb))\n",
        "models.append(('MLP', clf_mlp))\n",
        "models.append(('AB', clf_adaboost))\n",
        "models.append(('XGB', clf_xgb))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_WzJMzsjrL4"
      },
      "outputs": [],
      "source": [
        "def run_clf_cv(band, channel, label, clf):\n",
        "  if (band == \"theta\"):\n",
        "    df_x = df_theta\n",
        "  elif (band == \"alpha\"):\n",
        "    df_x = df_alpha\n",
        "  elif (band == \"beta\"):\n",
        "    df_x = df_beta\n",
        "  elif (band == \"gamma\"):\n",
        "    df_x = df_gamma\n",
        "\n",
        "  if (channel == \"frontal\"):\n",
        "    df_x = df_x[frontal]\n",
        "  elif (channel == \"central\"):\n",
        "    df_x = df_x[central]\n",
        "  elif (channel == \"parietal\"):\n",
        "    df_x = df_x[parietal]\n",
        "  elif (channel == \"occipital\"):\n",
        "    df_x = df_x[occipital]\n",
        "\n",
        "  # df_y = df_arousal if (label == \"arousal\") else df_valence\n",
        "  # print(df_y.shape)\n",
        "  # df_y = df_result[\"HAHV\"]\n",
        "  # df_y = df_result\n",
        "  # df_y = df_y.flatten\n",
        "  # print(f\"the shape of df_y is {df_y.shape}\")\n",
        "  # print(f\"the shape of df_x is {df_x.shape}\")\n",
        "  if (label == \"HAHV\"):\n",
        "    df_y = df_result[\"HAHV\"]\n",
        "  elif (label == \"LAHV\"):\n",
        "    df_y = df_result[\"LAHV\"]\n",
        "  elif (label == \"HALV\"):\n",
        "    df_y = df_result[\"HALV\"]\n",
        "  elif (label == \"LALV\"):\n",
        "    df_y = df_result[\"LALV\"]\n",
        "\n",
        "  # print(f\"the shape of df_y is {df_y.shape}\")\n",
        "  # print(f\"the shape of df_x is {df_x.shape}\")\n",
        "  # Train-test split\n",
        "\n",
        "  # save he dataframes in csv format for analysis\n",
        "  # if (band == \"gamma\" and channel == \"frontal\" and label == \"HALV\"):\n",
        "  #   df_y.to_csv('labels.csv', index=False)\n",
        "  #   print(\"DataFrame saved to 'labels.csv'\")\n",
        "  #   df_x.to_csv('data.csv', index=False)\n",
        "  #   print(\"DataFrame saved to 'data.csv'\")\n",
        "  #   from google.colab import files\n",
        "  #   files.download('labels.csv')\n",
        "  #   files.download('data.csv')\n",
        "\n",
        "  x_train, x_test, y_train, y_test = split_train_test(df_x, df_y)\n",
        "\n",
        "  # Apply CV\n",
        "  x_for_kfold = np.array(x_train)\n",
        "  y_for_kfold = np.array(y_train)\n",
        "  kfold = model_selection.KFold(n_splits=5)\n",
        "\n",
        "  for i, j in kfold.split(x_for_kfold):\n",
        "   x_train2, x_test2 = x_for_kfold[i], x_for_kfold[j]\n",
        "   y_train2, y_test2 = y_for_kfold[i], y_for_kfold[j]\n",
        "\n",
        "  # Feature scaling\n",
        "  x_train2, x_test2 = feature_scaling(x_train2, x_test2)\n",
        "\n",
        "  # Feature scaling\n",
        "  # scaler = StandardScaler()\n",
        "  # x_train2 = scaler.fit_transform(x_train2)\n",
        "  # x_test2 = scaler.transform(x_test2)\n",
        "\n",
        "\n",
        "  if (clf == \"svm\"):\n",
        "    clf_svm.fit(x_train2, y_train2)\n",
        "    y_predict = clf_svm.predict(x_test2)\n",
        "  elif (clf == \"knn\"):\n",
        "    clf_knn.fit(x_train2, y_train2)\n",
        "    y_predict = clf_knn.predict(x_test2)\n",
        "  elif (clf == \"dtree\"):\n",
        "    clf_dtree.fit(x_train2, y_train2)\n",
        "    y_predict = clf_dtree.predict(x_test2)\n",
        "  elif (clf == \"rf\"):\n",
        "    clf_rf.fit(x_train2, y_train2)\n",
        "    y_predict = clf_rf.predict(x_test2)\n",
        "  elif (clf == \"nb\"):\n",
        "    clf_nb.fit(x_train2, y_train2)\n",
        "    y_predict = clf_nb.predict(x_test2)\n",
        "  elif (clf == \"mlp\"):\n",
        "    clf_mlp.fit(x_train2, y_train2)\n",
        "    y_predict = clf_mlp.predict(x_test2)\n",
        "  elif (clf == \"ab\"):\n",
        "    clf_adaboost.fit(x_train2, y_train2)\n",
        "    y_predict = clf_adaboost.predict(x_test2)\n",
        "  elif (clf == \"xgb\"):\n",
        "    clf_xgb.fit(x_train2, y_train2)\n",
        "    y_predict = clf_xgb.predict(x_test2)\n",
        "  elif (clf == \"lgbm\"):\n",
        "    clf_lgbm.fit(x_train2, y_train2)\n",
        "    y_predict = clf_lgbm.predict(x_test2)\n",
        "  elif (clf == \"gpc\"):\n",
        "    clf_gpc.fit(x_train2, y_train2)\n",
        "    y_predict = clf_gpc.predict(x_test2)\n",
        "  elif (clf == \"per\"):\n",
        "    clf_perceptron.fit(x_train2, y_train2)\n",
        "    y_predict = clf_perceptron.predict(x_test2)\n",
        "  elif (clf == \"cb\"):\n",
        "    clf_catboost.fit(x_train2, y_train2)\n",
        "    y_predict = clf_catboost.predict(x_test2)\n",
        "  elif (clf == \"cnn\"):\n",
        "    # Evaluate the model on the test set\n",
        "    test_loss, test_accuracy = train_and_evaluate_cnn(df_x, df_y)\n",
        "    # print(f\"Test Loss: {test_loss}\")\n",
        "    # print(f\"Test Accuracy: {test_accuracy}\")\n",
        "    return \"DL\",test_loss, test_accuracy\n",
        "\n",
        "  elif(clf ==\"ann\"):\n",
        "    test_loss, test_accuracy = train_and_evaluate_ann(df_x, df_y)\n",
        "    # print(f\"Test Loss: {test_loss}\")\n",
        "    # print(f\"Test Accuracy: {test_accuracy}\")\n",
        "    return \"DL\",test_loss, test_accuracy\n",
        "  elif(clf ==\"lstm\"):\n",
        "    test_loss, test_accuracy = train_and_evaluate_lstm(df_x, df_y)\n",
        "    return \"DL\",test_loss,test_accuracy\n",
        "  return \"ML\",y_test2, y_predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gWN0kvbJjyhB"
      },
      "outputs": [],
      "source": [
        "def get_accuracy(band, channel, label, clf):\n",
        "  classifier,y_test2, y_predict = run_clf_cv(band, channel, label, clf)\n",
        "  if (classifier == \"DL\"):\n",
        "    return y_predict\n",
        "  return np.round(accuracy_score(y_test2, y_predict)*100,2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cB-1MOCIuv_M"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "def print_conf(band, channel, label, clf):\n",
        "  y_test2, y_predict = run_clf_cv(band, channel, label, clf)\n",
        "  conf_matrix = confusion_matrix(y_test2, y_predict)\n",
        "  # print(conf_matrix)\n",
        "  plt.figure(figsize=(4, 2))  # Decrease the figure size\n",
        "  plt.title('Confusion Matrix')\n",
        "  sns.heatmap(conf_matrix,\n",
        "              annot=True,\n",
        "              fmt='g',\n",
        "              xticklabels=['Not Spam','Spam'],\n",
        "              yticklabels=['Not Spam','Spam'])\n",
        "\n",
        "  # display matrix\n",
        "  plt.ylabel('Actual',fontsize=12)\n",
        "  plt.xlabel('Prediction',fontsize=12)\n",
        "  plt.show()\n",
        "\n",
        "  # printing the classification report aswell\n",
        "\n",
        "  class_report = classification_report(y_test2, y_predict, target_names=['Not Spam', 'Spam'])\n",
        "  print(\"\\nClassification Report:\")\n",
        "  print(class_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kBo9bznkFa9"
      },
      "outputs": [],
      "source": [
        "def print_accuracy(label, clf):\n",
        "  arr = []\n",
        "  for i in range (len(band_names)):\n",
        "    for j in range (len(channel_names)):\n",
        "      arr.append(get_accuracy(band_names[i], channel_names[j], label, clf))\n",
        "  arr = np.reshape(arr, (4,4))\n",
        "  df = pd.DataFrame(data = arr, index=band_names, columns=channel_names)\n",
        "\n",
        "  #print(\"Top 3 EEG regions with highest scores\")\n",
        "  #print(df.apply(lambda s: s.abs()).max().nlargest(3))\n",
        "  #print()\n",
        "  #print(\"Top 2 bands with highest scores\")\n",
        "  #print(df.apply(lambda s: s.abs()).max(axis=1).nlargest(2))\n",
        "  #print()\n",
        "  #print(\"EEG region with highest scores per each band\")\n",
        "  #print(df.idxmax(axis=1))\n",
        "  #print()\n",
        "  #print(\"Accuracy Scores\")\n",
        "  #print(df.idxmax())\n",
        "  #print()\n",
        "  print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDIaK777kOdU",
        "outputId": "48234377-d1c5-4bbe-d3f4-cad467c7bfb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    68.63    69.61     69.12      68.63\n",
            "alpha    68.63    70.10     69.12      68.63\n",
            "beta     70.10    69.61     70.10      70.10\n",
            "gamma    69.61    69.61     70.10      69.61\n"
          ]
        }
      ],
      "source": [
        "print_accuracy('HAHV', 'svm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RfE3GdBoXXlK"
      },
      "outputs": [],
      "source": [
        "print_conf(\"beta\",\"frontal\",\"HAHV\",\"svm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTqPyKdifUch"
      },
      "outputs": [],
      "source": [
        "print_accuracy('LAHV', 'svm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bv-yHWWNXq4F"
      },
      "outputs": [],
      "source": [
        "print_conf(\"theta\",\"occipital\",\"LAHV\",\"svm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BaV8Ul3zfbVG"
      },
      "outputs": [],
      "source": [
        "print_accuracy('HALV', 'svm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsXUXB_mX4Yq"
      },
      "outputs": [],
      "source": [
        "print_conf(\"gamma\",\"frontal\",\"HALV\",\"svm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8sPz6Kjdfkia"
      },
      "outputs": [],
      "source": [
        "print_accuracy('LALV', 'svm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IytKfnprYIKG"
      },
      "outputs": [],
      "source": [
        "print_conf(\"gamma\",\"occipital\",\"LALV\",\"svm\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"LALV\",\"ann\")"
      ],
      "metadata": {
        "id": "3ZJ1eRTBagJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"HALV\",\"lstm\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47cLDLLtc3dL",
        "outputId": "571393d7-9b6a-4fb9-cb5a-12f15bc17912"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "32/32 [==============================] - 9s 67ms/step - loss: 0.6641 - accuracy: 0.6357 - val_loss: 0.5201 - val_accuracy: 0.7930\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5913 - accuracy: 0.7529 - val_loss: 0.5151 - val_accuracy: 0.7930\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5653 - accuracy: 0.7559 - val_loss: 0.5125 - val_accuracy: 0.7930\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5797 - accuracy: 0.7656 - val_loss: 0.5179 - val_accuracy: 0.7930\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5664 - accuracy: 0.7686 - val_loss: 0.5146 - val_accuracy: 0.7930\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5568 - accuracy: 0.7705 - val_loss: 0.5167 - val_accuracy: 0.7930\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5572 - accuracy: 0.7725 - val_loss: 0.5144 - val_accuracy: 0.7930\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5470 - accuracy: 0.7734 - val_loss: 0.5190 - val_accuracy: 0.7930\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5704 - accuracy: 0.7754 - val_loss: 0.5166 - val_accuracy: 0.7930\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5542 - accuracy: 0.7764 - val_loss: 0.5177 - val_accuracy: 0.7930\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5475 - accuracy: 0.7764 - val_loss: 0.5187 - val_accuracy: 0.7930\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5431 - accuracy: 0.7764 - val_loss: 0.5156 - val_accuracy: 0.7930\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5513 - accuracy: 0.7773 - val_loss: 0.5152 - val_accuracy: 0.7930\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5432 - accuracy: 0.7764 - val_loss: 0.5199 - val_accuracy: 0.7930\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5360 - accuracy: 0.7764 - val_loss: 0.5181 - val_accuracy: 0.7930\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5416 - accuracy: 0.7764 - val_loss: 0.5185 - val_accuracy: 0.7930\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5401 - accuracy: 0.7764 - val_loss: 0.5160 - val_accuracy: 0.7930\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5441 - accuracy: 0.7764 - val_loss: 0.5225 - val_accuracy: 0.7930\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5400 - accuracy: 0.7764 - val_loss: 0.5166 - val_accuracy: 0.7930\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5447 - accuracy: 0.7754 - val_loss: 0.5212 - val_accuracy: 0.7930\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5362 - accuracy: 0.7764 - val_loss: 0.5191 - val_accuracy: 0.7930\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5418 - accuracy: 0.7754 - val_loss: 0.5189 - val_accuracy: 0.7930\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5266 - accuracy: 0.7764 - val_loss: 0.5141 - val_accuracy: 0.7930\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5445 - accuracy: 0.7764 - val_loss: 0.5225 - val_accuracy: 0.7930\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5349 - accuracy: 0.7764 - val_loss: 0.5217 - val_accuracy: 0.7930\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5360 - accuracy: 0.7764 - val_loss: 0.5151 - val_accuracy: 0.7930\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5309 - accuracy: 0.7764 - val_loss: 0.5170 - val_accuracy: 0.7930\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5406 - accuracy: 0.7764 - val_loss: 0.5224 - val_accuracy: 0.7930\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5480 - accuracy: 0.7764 - val_loss: 0.5281 - val_accuracy: 0.7930\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5281 - accuracy: 0.7764 - val_loss: 0.5155 - val_accuracy: 0.7930\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5315 - accuracy: 0.7764 - val_loss: 0.5151 - val_accuracy: 0.7930\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5411 - accuracy: 0.7764 - val_loss: 0.5195 - val_accuracy: 0.7930\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5381 - accuracy: 0.7764 - val_loss: 0.5177 - val_accuracy: 0.7930\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5339 - accuracy: 0.7764 - val_loss: 0.5170 - val_accuracy: 0.7930\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5382 - accuracy: 0.7764 - val_loss: 0.5181 - val_accuracy: 0.7930\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5346 - accuracy: 0.7764 - val_loss: 0.5154 - val_accuracy: 0.7930\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5376 - accuracy: 0.7764 - val_loss: 0.5180 - val_accuracy: 0.7930\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5326 - accuracy: 0.7764 - val_loss: 0.5141 - val_accuracy: 0.7930\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5341 - accuracy: 0.7764 - val_loss: 0.5158 - val_accuracy: 0.7930\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5369 - accuracy: 0.7764 - val_loss: 0.5120 - val_accuracy: 0.7930\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5351 - accuracy: 0.7764 - val_loss: 0.5220 - val_accuracy: 0.7930\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5362 - accuracy: 0.7764 - val_loss: 0.5176 - val_accuracy: 0.7930\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5372 - accuracy: 0.7764 - val_loss: 0.5165 - val_accuracy: 0.7930\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5272 - accuracy: 0.7764 - val_loss: 0.5137 - val_accuracy: 0.7930\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5268 - accuracy: 0.7764 - val_loss: 0.5148 - val_accuracy: 0.7930\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5331 - accuracy: 0.7764 - val_loss: 0.5131 - val_accuracy: 0.7930\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5272 - accuracy: 0.7764 - val_loss: 0.5106 - val_accuracy: 0.7930\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5244 - accuracy: 0.7764 - val_loss: 0.5116 - val_accuracy: 0.7930\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5302 - accuracy: 0.7764 - val_loss: 0.5136 - val_accuracy: 0.7930\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5374 - accuracy: 0.7764 - val_loss: 0.5150 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5150 - accuracy: 0.7930\n",
            "Epoch 1/50\n",
            "32/32 [==============================] - 3s 31ms/step - loss: 0.6318 - accuracy: 0.7109 - val_loss: 0.5240 - val_accuracy: 0.7930\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5989 - accuracy: 0.7500 - val_loss: 0.5253 - val_accuracy: 0.7930\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5668 - accuracy: 0.7559 - val_loss: 0.5302 - val_accuracy: 0.7930\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5749 - accuracy: 0.7617 - val_loss: 0.5303 - val_accuracy: 0.7930\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5515 - accuracy: 0.7695 - val_loss: 0.5331 - val_accuracy: 0.7930\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5403 - accuracy: 0.7734 - val_loss: 0.5343 - val_accuracy: 0.7930\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5504 - accuracy: 0.7695 - val_loss: 0.5332 - val_accuracy: 0.7930\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5627 - accuracy: 0.7686 - val_loss: 0.5312 - val_accuracy: 0.7930\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5529 - accuracy: 0.7695 - val_loss: 0.5313 - val_accuracy: 0.7930\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5426 - accuracy: 0.7754 - val_loss: 0.5356 - val_accuracy: 0.7930\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5384 - accuracy: 0.7744 - val_loss: 0.5279 - val_accuracy: 0.7930\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5320 - accuracy: 0.7754 - val_loss: 0.5319 - val_accuracy: 0.7930\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5489 - accuracy: 0.7754 - val_loss: 0.5367 - val_accuracy: 0.7930\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5400 - accuracy: 0.7764 - val_loss: 0.5272 - val_accuracy: 0.7930\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5494 - accuracy: 0.7764 - val_loss: 0.5284 - val_accuracy: 0.7930\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5326 - accuracy: 0.7764 - val_loss: 0.5262 - val_accuracy: 0.7930\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5267 - accuracy: 0.7764 - val_loss: 0.5277 - val_accuracy: 0.7930\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5414 - accuracy: 0.7764 - val_loss: 0.5353 - val_accuracy: 0.7930\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5379 - accuracy: 0.7764 - val_loss: 0.5321 - val_accuracy: 0.7930\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5292 - accuracy: 0.7764 - val_loss: 0.5280 - val_accuracy: 0.7930\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5387 - accuracy: 0.7764 - val_loss: 0.5282 - val_accuracy: 0.7930\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5429 - accuracy: 0.7764 - val_loss: 0.5297 - val_accuracy: 0.7930\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5341 - accuracy: 0.7764 - val_loss: 0.5282 - val_accuracy: 0.7930\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5328 - accuracy: 0.7764 - val_loss: 0.5250 - val_accuracy: 0.7930\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5387 - accuracy: 0.7764 - val_loss: 0.5326 - val_accuracy: 0.7930\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5285 - accuracy: 0.7764 - val_loss: 0.5286 - val_accuracy: 0.7930\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5361 - accuracy: 0.7764 - val_loss: 0.5314 - val_accuracy: 0.7930\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5348 - accuracy: 0.7764 - val_loss: 0.5293 - val_accuracy: 0.7930\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5362 - accuracy: 0.7764 - val_loss: 0.5277 - val_accuracy: 0.7930\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5323 - accuracy: 0.7764 - val_loss: 0.5239 - val_accuracy: 0.7930\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5303 - accuracy: 0.7764 - val_loss: 0.5259 - val_accuracy: 0.7930\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5321 - accuracy: 0.7764 - val_loss: 0.5286 - val_accuracy: 0.7930\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5306 - accuracy: 0.7764 - val_loss: 0.5280 - val_accuracy: 0.7930\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5279 - accuracy: 0.7764 - val_loss: 0.5210 - val_accuracy: 0.7930\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5326 - accuracy: 0.7764 - val_loss: 0.5239 - val_accuracy: 0.7930\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5253 - accuracy: 0.7764 - val_loss: 0.5228 - val_accuracy: 0.7930\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5311 - accuracy: 0.7764 - val_loss: 0.5254 - val_accuracy: 0.7930\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5310 - accuracy: 0.7764 - val_loss: 0.5229 - val_accuracy: 0.7930\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5290 - accuracy: 0.7764 - val_loss: 0.5227 - val_accuracy: 0.7930\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5241 - accuracy: 0.7764 - val_loss: 0.5184 - val_accuracy: 0.7930\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5292 - accuracy: 0.7764 - val_loss: 0.5184 - val_accuracy: 0.7930\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5242 - accuracy: 0.7764 - val_loss: 0.5192 - val_accuracy: 0.7930\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5224 - accuracy: 0.7764 - val_loss: 0.5154 - val_accuracy: 0.7930\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5264 - accuracy: 0.7764 - val_loss: 0.5174 - val_accuracy: 0.7930\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5324 - accuracy: 0.7764 - val_loss: 0.5198 - val_accuracy: 0.7930\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5263 - accuracy: 0.7764 - val_loss: 0.5205 - val_accuracy: 0.7930\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5255 - accuracy: 0.7764 - val_loss: 0.5168 - val_accuracy: 0.7930\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5268 - accuracy: 0.7764 - val_loss: 0.5168 - val_accuracy: 0.7930\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5261 - accuracy: 0.7764 - val_loss: 0.5132 - val_accuracy: 0.7930\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5263 - accuracy: 0.7764 - val_loss: 0.5117 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5117 - accuracy: 0.7930\n",
            "Epoch 1/50\n",
            "32/32 [==============================] - 3s 21ms/step - loss: 0.6244 - accuracy: 0.6787 - val_loss: 0.5122 - val_accuracy: 0.7930\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5506 - accuracy: 0.7705 - val_loss: 0.5039 - val_accuracy: 0.7930\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5734 - accuracy: 0.7783 - val_loss: 0.5065 - val_accuracy: 0.7930\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5622 - accuracy: 0.7715 - val_loss: 0.5066 - val_accuracy: 0.7930\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5448 - accuracy: 0.7754 - val_loss: 0.5067 - val_accuracy: 0.7930\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5572 - accuracy: 0.7764 - val_loss: 0.5086 - val_accuracy: 0.7930\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5476 - accuracy: 0.7744 - val_loss: 0.5117 - val_accuracy: 0.7930\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5384 - accuracy: 0.7764 - val_loss: 0.5089 - val_accuracy: 0.7930\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5553 - accuracy: 0.7754 - val_loss: 0.5126 - val_accuracy: 0.7930\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5332 - accuracy: 0.7754 - val_loss: 0.5089 - val_accuracy: 0.7930\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5443 - accuracy: 0.7764 - val_loss: 0.5103 - val_accuracy: 0.7930\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5360 - accuracy: 0.7764 - val_loss: 0.5131 - val_accuracy: 0.7930\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5450 - accuracy: 0.7764 - val_loss: 0.5075 - val_accuracy: 0.7930\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5425 - accuracy: 0.7764 - val_loss: 0.5156 - val_accuracy: 0.7930\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5362 - accuracy: 0.7764 - val_loss: 0.5082 - val_accuracy: 0.7930\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5318 - accuracy: 0.7764 - val_loss: 0.5113 - val_accuracy: 0.7930\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5420 - accuracy: 0.7764 - val_loss: 0.5137 - val_accuracy: 0.7930\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5349 - accuracy: 0.7764 - val_loss: 0.5139 - val_accuracy: 0.7930\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5347 - accuracy: 0.7764 - val_loss: 0.5142 - val_accuracy: 0.7930\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5255 - accuracy: 0.7764 - val_loss: 0.5108 - val_accuracy: 0.7930\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5321 - accuracy: 0.7764 - val_loss: 0.5108 - val_accuracy: 0.7930\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5297 - accuracy: 0.7764 - val_loss: 0.5114 - val_accuracy: 0.7930\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5351 - accuracy: 0.7764 - val_loss: 0.5111 - val_accuracy: 0.7930\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5294 - accuracy: 0.7764 - val_loss: 0.5099 - val_accuracy: 0.7930\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5316 - accuracy: 0.7764 - val_loss: 0.5121 - val_accuracy: 0.7930\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5355 - accuracy: 0.7764 - val_loss: 0.5102 - val_accuracy: 0.7930\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5370 - accuracy: 0.7764 - val_loss: 0.5120 - val_accuracy: 0.7930\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5285 - accuracy: 0.7764 - val_loss: 0.5119 - val_accuracy: 0.7930\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5296 - accuracy: 0.7764 - val_loss: 0.5110 - val_accuracy: 0.7930\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5272 - accuracy: 0.7764 - val_loss: 0.5121 - val_accuracy: 0.7930\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5329 - accuracy: 0.7764 - val_loss: 0.5112 - val_accuracy: 0.7930\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5348 - accuracy: 0.7764 - val_loss: 0.5096 - val_accuracy: 0.7930\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5279 - accuracy: 0.7764 - val_loss: 0.5114 - val_accuracy: 0.7930\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5319 - accuracy: 0.7764 - val_loss: 0.5106 - val_accuracy: 0.7930\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5274 - accuracy: 0.7764 - val_loss: 0.5104 - val_accuracy: 0.7930\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5261 - accuracy: 0.7764 - val_loss: 0.5074 - val_accuracy: 0.7930\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5231 - accuracy: 0.7764 - val_loss: 0.5081 - val_accuracy: 0.7930\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5282 - accuracy: 0.7764 - val_loss: 0.5094 - val_accuracy: 0.7930\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5267 - accuracy: 0.7764 - val_loss: 0.5100 - val_accuracy: 0.7930\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5296 - accuracy: 0.7764 - val_loss: 0.5117 - val_accuracy: 0.7930\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5278 - accuracy: 0.7764 - val_loss: 0.5132 - val_accuracy: 0.7930\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5252 - accuracy: 0.7764 - val_loss: 0.5114 - val_accuracy: 0.7930\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5316 - accuracy: 0.7764 - val_loss: 0.5080 - val_accuracy: 0.7930\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5199 - accuracy: 0.7764 - val_loss: 0.5080 - val_accuracy: 0.7930\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5289 - accuracy: 0.7764 - val_loss: 0.5103 - val_accuracy: 0.7930\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5298 - accuracy: 0.7764 - val_loss: 0.5119 - val_accuracy: 0.7930\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5244 - accuracy: 0.7764 - val_loss: 0.5084 - val_accuracy: 0.7930\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5318 - accuracy: 0.7764 - val_loss: 0.5083 - val_accuracy: 0.7930\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5270 - accuracy: 0.7764 - val_loss: 0.5092 - val_accuracy: 0.7930\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5284 - accuracy: 0.7764 - val_loss: 0.5074 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7930\n",
            "Epoch 1/50\n",
            "32/32 [==============================] - 3s 21ms/step - loss: 0.5760 - accuracy: 0.7529 - val_loss: 0.5138 - val_accuracy: 0.7930\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5761 - accuracy: 0.7715 - val_loss: 0.5190 - val_accuracy: 0.7930\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5706 - accuracy: 0.7744 - val_loss: 0.5177 - val_accuracy: 0.7930\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5546 - accuracy: 0.7764 - val_loss: 0.5176 - val_accuracy: 0.7930\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5518 - accuracy: 0.7764 - val_loss: 0.5182 - val_accuracy: 0.7930\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5465 - accuracy: 0.7764 - val_loss: 0.5193 - val_accuracy: 0.7930\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5441 - accuracy: 0.7764 - val_loss: 0.5229 - val_accuracy: 0.7930\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5433 - accuracy: 0.7764 - val_loss: 0.5212 - val_accuracy: 0.7930\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5474 - accuracy: 0.7764 - val_loss: 0.5294 - val_accuracy: 0.7930\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5429 - accuracy: 0.7764 - val_loss: 0.5284 - val_accuracy: 0.7930\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5408 - accuracy: 0.7764 - val_loss: 0.5284 - val_accuracy: 0.7930\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5292 - accuracy: 0.7764 - val_loss: 0.5261 - val_accuracy: 0.7930\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5365 - accuracy: 0.7764 - val_loss: 0.5233 - val_accuracy: 0.7930\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5414 - accuracy: 0.7764 - val_loss: 0.5278 - val_accuracy: 0.7930\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5413 - accuracy: 0.7764 - val_loss: 0.5248 - val_accuracy: 0.7930\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5383 - accuracy: 0.7764 - val_loss: 0.5243 - val_accuracy: 0.7930\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5364 - accuracy: 0.7764 - val_loss: 0.5204 - val_accuracy: 0.7930\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5354 - accuracy: 0.7764 - val_loss: 0.5221 - val_accuracy: 0.7930\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5475 - accuracy: 0.7764 - val_loss: 0.5257 - val_accuracy: 0.7930\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5338 - accuracy: 0.7764 - val_loss: 0.5250 - val_accuracy: 0.7930\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5397 - accuracy: 0.7764 - val_loss: 0.5251 - val_accuracy: 0.7930\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5359 - accuracy: 0.7764 - val_loss: 0.5201 - val_accuracy: 0.7930\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5344 - accuracy: 0.7764 - val_loss: 0.5165 - val_accuracy: 0.7930\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5311 - accuracy: 0.7764 - val_loss: 0.5154 - val_accuracy: 0.7930\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5382 - accuracy: 0.7764 - val_loss: 0.5191 - val_accuracy: 0.7930\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5431 - accuracy: 0.7764 - val_loss: 0.5219 - val_accuracy: 0.7930\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5318 - accuracy: 0.7764 - val_loss: 0.5224 - val_accuracy: 0.7930\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5294 - accuracy: 0.7764 - val_loss: 0.5194 - val_accuracy: 0.7930\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5318 - accuracy: 0.7764 - val_loss: 0.5221 - val_accuracy: 0.7930\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5321 - accuracy: 0.7764 - val_loss: 0.5212 - val_accuracy: 0.7930\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5373 - accuracy: 0.7764 - val_loss: 0.5244 - val_accuracy: 0.7930\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5417 - accuracy: 0.7764 - val_loss: 0.5262 - val_accuracy: 0.7930\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5335 - accuracy: 0.7764 - val_loss: 0.5237 - val_accuracy: 0.7930\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5372 - accuracy: 0.7764 - val_loss: 0.5261 - val_accuracy: 0.7930\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5320 - accuracy: 0.7764 - val_loss: 0.5204 - val_accuracy: 0.7930\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5350 - accuracy: 0.7764 - val_loss: 0.5245 - val_accuracy: 0.7930\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5304 - accuracy: 0.7764 - val_loss: 0.5245 - val_accuracy: 0.7930\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5339 - accuracy: 0.7764 - val_loss: 0.5186 - val_accuracy: 0.7930\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5389 - accuracy: 0.7764 - val_loss: 0.5206 - val_accuracy: 0.7930\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5293 - accuracy: 0.7764 - val_loss: 0.5212 - val_accuracy: 0.7930\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5328 - accuracy: 0.7764 - val_loss: 0.5195 - val_accuracy: 0.7930\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5344 - accuracy: 0.7764 - val_loss: 0.5214 - val_accuracy: 0.7930\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5298 - accuracy: 0.7764 - val_loss: 0.5209 - val_accuracy: 0.7930\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5349 - accuracy: 0.7764 - val_loss: 0.5207 - val_accuracy: 0.7930\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5332 - accuracy: 0.7764 - val_loss: 0.5207 - val_accuracy: 0.7930\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5352 - accuracy: 0.7764 - val_loss: 0.5178 - val_accuracy: 0.7930\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5302 - accuracy: 0.7764 - val_loss: 0.5187 - val_accuracy: 0.7930\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5288 - accuracy: 0.7764 - val_loss: 0.5156 - val_accuracy: 0.7930\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5366 - accuracy: 0.7764 - val_loss: 0.5194 - val_accuracy: 0.7930\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5318 - accuracy: 0.7764 - val_loss: 0.5158 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5158 - accuracy: 0.7930\n",
            "Epoch 1/50\n",
            "32/32 [==============================] - 3s 22ms/step - loss: 0.7580 - accuracy: 0.5088 - val_loss: 0.5274 - val_accuracy: 0.7930\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5878 - accuracy: 0.7568 - val_loss: 0.5122 - val_accuracy: 0.7930\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5836 - accuracy: 0.7568 - val_loss: 0.5111 - val_accuracy: 0.7930\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5706 - accuracy: 0.7783 - val_loss: 0.5131 - val_accuracy: 0.7930\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5629 - accuracy: 0.7725 - val_loss: 0.5149 - val_accuracy: 0.7930\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5536 - accuracy: 0.7725 - val_loss: 0.5095 - val_accuracy: 0.7930\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5522 - accuracy: 0.7666 - val_loss: 0.5092 - val_accuracy: 0.7930\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5533 - accuracy: 0.7686 - val_loss: 0.5087 - val_accuracy: 0.7930\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5475 - accuracy: 0.7734 - val_loss: 0.5070 - val_accuracy: 0.7930\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5360 - accuracy: 0.7773 - val_loss: 0.5056 - val_accuracy: 0.7930\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5430 - accuracy: 0.7754 - val_loss: 0.5080 - val_accuracy: 0.7930\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5427 - accuracy: 0.7754 - val_loss: 0.5082 - val_accuracy: 0.7930\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5329 - accuracy: 0.7764 - val_loss: 0.5082 - val_accuracy: 0.7930\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5433 - accuracy: 0.7754 - val_loss: 0.5084 - val_accuracy: 0.7930\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5291 - accuracy: 0.7764 - val_loss: 0.5057 - val_accuracy: 0.7930\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5272 - accuracy: 0.7764 - val_loss: 0.5034 - val_accuracy: 0.7930\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5411 - accuracy: 0.7744 - val_loss: 0.5023 - val_accuracy: 0.7930\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5351 - accuracy: 0.7754 - val_loss: 0.5042 - val_accuracy: 0.7930\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5365 - accuracy: 0.7754 - val_loss: 0.5029 - val_accuracy: 0.7930\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5374 - accuracy: 0.7754 - val_loss: 0.5021 - val_accuracy: 0.7930\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5329 - accuracy: 0.7764 - val_loss: 0.5012 - val_accuracy: 0.7930\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5332 - accuracy: 0.7764 - val_loss: 0.5025 - val_accuracy: 0.7930\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5385 - accuracy: 0.7764 - val_loss: 0.5094 - val_accuracy: 0.7930\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5239 - accuracy: 0.7764 - val_loss: 0.4991 - val_accuracy: 0.7930\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5355 - accuracy: 0.7764 - val_loss: 0.4993 - val_accuracy: 0.7930\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5252 - accuracy: 0.7764 - val_loss: 0.4987 - val_accuracy: 0.7930\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5271 - accuracy: 0.7764 - val_loss: 0.4993 - val_accuracy: 0.7930\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5341 - accuracy: 0.7764 - val_loss: 0.5019 - val_accuracy: 0.7930\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5290 - accuracy: 0.7754 - val_loss: 0.5022 - val_accuracy: 0.7930\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5285 - accuracy: 0.7764 - val_loss: 0.5004 - val_accuracy: 0.7930\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5252 - accuracy: 0.7764 - val_loss: 0.4989 - val_accuracy: 0.7930\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5288 - accuracy: 0.7764 - val_loss: 0.4994 - val_accuracy: 0.7930\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5298 - accuracy: 0.7764 - val_loss: 0.5014 - val_accuracy: 0.7930\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5251 - accuracy: 0.7764 - val_loss: 0.5003 - val_accuracy: 0.7930\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5196 - accuracy: 0.7764 - val_loss: 0.4947 - val_accuracy: 0.7930\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5211 - accuracy: 0.7764 - val_loss: 0.4991 - val_accuracy: 0.7930\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.5270 - accuracy: 0.7764 - val_loss: 0.4900 - val_accuracy: 0.7930\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5152 - accuracy: 0.7764 - val_loss: 0.4934 - val_accuracy: 0.7930\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5184 - accuracy: 0.7764 - val_loss: 0.4933 - val_accuracy: 0.7930\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5250 - accuracy: 0.7764 - val_loss: 0.4981 - val_accuracy: 0.7930\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5257 - accuracy: 0.7764 - val_loss: 0.4981 - val_accuracy: 0.7930\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5203 - accuracy: 0.7764 - val_loss: 0.4913 - val_accuracy: 0.7930\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5218 - accuracy: 0.7764 - val_loss: 0.5012 - val_accuracy: 0.7930\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5221 - accuracy: 0.7764 - val_loss: 0.4994 - val_accuracy: 0.7930\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5248 - accuracy: 0.7764 - val_loss: 0.4981 - val_accuracy: 0.7930\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5235 - accuracy: 0.7764 - val_loss: 0.4991 - val_accuracy: 0.7930\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5258 - accuracy: 0.7764 - val_loss: 0.4970 - val_accuracy: 0.7930\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5237 - accuracy: 0.7764 - val_loss: 0.4976 - val_accuracy: 0.7930\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5179 - accuracy: 0.7764 - val_loss: 0.4949 - val_accuracy: 0.7930\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5236 - accuracy: 0.7764 - val_loss: 0.4975 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4975 - accuracy: 0.7930\n",
            "Epoch 1/50\n",
            "32/32 [==============================] - 3s 24ms/step - loss: 0.6401 - accuracy: 0.6680 - val_loss: 0.5140 - val_accuracy: 0.7930\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5599 - accuracy: 0.7695 - val_loss: 0.5096 - val_accuracy: 0.7930\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5754 - accuracy: 0.7705 - val_loss: 0.5179 - val_accuracy: 0.7930\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5591 - accuracy: 0.7734 - val_loss: 0.5148 - val_accuracy: 0.7930\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5536 - accuracy: 0.7725 - val_loss: 0.5155 - val_accuracy: 0.7930\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5491 - accuracy: 0.7744 - val_loss: 0.5093 - val_accuracy: 0.7930\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5463 - accuracy: 0.7764 - val_loss: 0.5144 - val_accuracy: 0.7930\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5435 - accuracy: 0.7764 - val_loss: 0.5120 - val_accuracy: 0.7930\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5432 - accuracy: 0.7764 - val_loss: 0.5134 - val_accuracy: 0.7930\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5426 - accuracy: 0.7764 - val_loss: 0.5131 - val_accuracy: 0.7930\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5418 - accuracy: 0.7764 - val_loss: 0.5155 - val_accuracy: 0.7930\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5439 - accuracy: 0.7764 - val_loss: 0.5168 - val_accuracy: 0.7930\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5371 - accuracy: 0.7773 - val_loss: 0.5175 - val_accuracy: 0.7930\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5386 - accuracy: 0.7764 - val_loss: 0.5172 - val_accuracy: 0.7930\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5284 - accuracy: 0.7764 - val_loss: 0.5133 - val_accuracy: 0.7930\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5275 - accuracy: 0.7764 - val_loss: 0.5141 - val_accuracy: 0.7930\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5478 - accuracy: 0.7764 - val_loss: 0.5156 - val_accuracy: 0.7930\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5373 - accuracy: 0.7764 - val_loss: 0.5186 - val_accuracy: 0.7930\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5328 - accuracy: 0.7764 - val_loss: 0.5121 - val_accuracy: 0.7930\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5337 - accuracy: 0.7764 - val_loss: 0.5141 - val_accuracy: 0.7930\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5381 - accuracy: 0.7764 - val_loss: 0.5160 - val_accuracy: 0.7930\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5355 - accuracy: 0.7764 - val_loss: 0.5154 - val_accuracy: 0.7930\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5361 - accuracy: 0.7764 - val_loss: 0.5202 - val_accuracy: 0.7930\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5322 - accuracy: 0.7764 - val_loss: 0.5168 - val_accuracy: 0.7930\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5312 - accuracy: 0.7764 - val_loss: 0.5171 - val_accuracy: 0.7930\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5338 - accuracy: 0.7764 - val_loss: 0.5151 - val_accuracy: 0.7930\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5243 - accuracy: 0.7764 - val_loss: 0.5140 - val_accuracy: 0.7930\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5330 - accuracy: 0.7764 - val_loss: 0.5125 - val_accuracy: 0.7930\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5298 - accuracy: 0.7764 - val_loss: 0.5142 - val_accuracy: 0.7930\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5293 - accuracy: 0.7764 - val_loss: 0.5135 - val_accuracy: 0.7930\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5322 - accuracy: 0.7764 - val_loss: 0.5169 - val_accuracy: 0.7930\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5204 - accuracy: 0.7764 - val_loss: 0.5123 - val_accuracy: 0.7930\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5366 - accuracy: 0.7764 - val_loss: 0.5170 - val_accuracy: 0.7930\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5284 - accuracy: 0.7764 - val_loss: 0.5148 - val_accuracy: 0.7930\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5319 - accuracy: 0.7764 - val_loss: 0.5163 - val_accuracy: 0.7930\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5318 - accuracy: 0.7764 - val_loss: 0.5163 - val_accuracy: 0.7930\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5295 - accuracy: 0.7764 - val_loss: 0.5165 - val_accuracy: 0.7930\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.5309 - accuracy: 0.7764 - val_loss: 0.5139 - val_accuracy: 0.7930\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.5255 - accuracy: 0.7764 - val_loss: 0.5135 - val_accuracy: 0.7930\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5292 - accuracy: 0.7764 - val_loss: 0.5123 - val_accuracy: 0.7930\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5331 - accuracy: 0.7764 - val_loss: 0.5145 - val_accuracy: 0.7930\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5318 - accuracy: 0.7764 - val_loss: 0.5122 - val_accuracy: 0.7930\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.5261 - accuracy: 0.7764 - val_loss: 0.5117 - val_accuracy: 0.7930\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5243 - accuracy: 0.7764 - val_loss: 0.5114 - val_accuracy: 0.7930\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5269 - accuracy: 0.7764 - val_loss: 0.5105 - val_accuracy: 0.7930\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5246 - accuracy: 0.7764 - val_loss: 0.5122 - val_accuracy: 0.7930\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5254 - accuracy: 0.7764 - val_loss: 0.5102 - val_accuracy: 0.7930\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5260 - accuracy: 0.7764 - val_loss: 0.5114 - val_accuracy: 0.7930\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5295 - accuracy: 0.7764 - val_loss: 0.5096 - val_accuracy: 0.7930\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5239 - accuracy: 0.7764 - val_loss: 0.5107 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5107 - accuracy: 0.7930\n",
            "Epoch 1/50\n",
            "32/32 [==============================] - 4s 36ms/step - loss: 0.6111 - accuracy: 0.6895 - val_loss: 0.5180 - val_accuracy: 0.7930\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5595 - accuracy: 0.7725 - val_loss: 0.5142 - val_accuracy: 0.7930\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.5474 - accuracy: 0.7715 - val_loss: 0.5175 - val_accuracy: 0.7930\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5634 - accuracy: 0.7666 - val_loss: 0.5186 - val_accuracy: 0.7930\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5581 - accuracy: 0.7734 - val_loss: 0.5149 - val_accuracy: 0.7930\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5504 - accuracy: 0.7754 - val_loss: 0.5163 - val_accuracy: 0.7930\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5530 - accuracy: 0.7764 - val_loss: 0.5140 - val_accuracy: 0.7930\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5487 - accuracy: 0.7764 - val_loss: 0.5162 - val_accuracy: 0.7930\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5468 - accuracy: 0.7764 - val_loss: 0.5235 - val_accuracy: 0.7930\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5446 - accuracy: 0.7764 - val_loss: 0.5153 - val_accuracy: 0.7930\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5576 - accuracy: 0.7764 - val_loss: 0.5235 - val_accuracy: 0.7930\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5457 - accuracy: 0.7764 - val_loss: 0.5165 - val_accuracy: 0.7930\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5426 - accuracy: 0.7764 - val_loss: 0.5128 - val_accuracy: 0.7930\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5403 - accuracy: 0.7764 - val_loss: 0.5178 - val_accuracy: 0.7930\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5430 - accuracy: 0.7764 - val_loss: 0.5154 - val_accuracy: 0.7930\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5468 - accuracy: 0.7764 - val_loss: 0.5215 - val_accuracy: 0.7930\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5403 - accuracy: 0.7764 - val_loss: 0.5221 - val_accuracy: 0.7930\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5412 - accuracy: 0.7764 - val_loss: 0.5167 - val_accuracy: 0.7930\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5320 - accuracy: 0.7764 - val_loss: 0.5139 - val_accuracy: 0.7930\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5340 - accuracy: 0.7764 - val_loss: 0.5164 - val_accuracy: 0.7930\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5325 - accuracy: 0.7764 - val_loss: 0.5150 - val_accuracy: 0.7930\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5287 - accuracy: 0.7764 - val_loss: 0.5146 - val_accuracy: 0.7930\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5372 - accuracy: 0.7764 - val_loss: 0.5149 - val_accuracy: 0.7930\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5301 - accuracy: 0.7764 - val_loss: 0.5132 - val_accuracy: 0.7930\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5364 - accuracy: 0.7764 - val_loss: 0.5137 - val_accuracy: 0.7930\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5226 - accuracy: 0.7764 - val_loss: 0.5128 - val_accuracy: 0.7930\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5329 - accuracy: 0.7764 - val_loss: 0.5175 - val_accuracy: 0.7930\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5274 - accuracy: 0.7764 - val_loss: 0.5129 - val_accuracy: 0.7930\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5310 - accuracy: 0.7764 - val_loss: 0.5165 - val_accuracy: 0.7930\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5279 - accuracy: 0.7764 - val_loss: 0.5129 - val_accuracy: 0.7930\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5296 - accuracy: 0.7764 - val_loss: 0.5140 - val_accuracy: 0.7930\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5341 - accuracy: 0.7764 - val_loss: 0.5133 - val_accuracy: 0.7930\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5233 - accuracy: 0.7764 - val_loss: 0.5132 - val_accuracy: 0.7930\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5326 - accuracy: 0.7764 - val_loss: 0.5164 - val_accuracy: 0.7930\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5313 - accuracy: 0.7764 - val_loss: 0.5143 - val_accuracy: 0.7930\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5303 - accuracy: 0.7764 - val_loss: 0.5138 - val_accuracy: 0.7930\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5288 - accuracy: 0.7764 - val_loss: 0.5151 - val_accuracy: 0.7930\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5374 - accuracy: 0.7764 - val_loss: 0.5164 - val_accuracy: 0.7930\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5284 - accuracy: 0.7764 - val_loss: 0.5143 - val_accuracy: 0.7930\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5289 - accuracy: 0.7764 - val_loss: 0.5124 - val_accuracy: 0.7930\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5246 - accuracy: 0.7764 - val_loss: 0.5102 - val_accuracy: 0.7930\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5305 - accuracy: 0.7764 - val_loss: 0.5112 - val_accuracy: 0.7930\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5286 - accuracy: 0.7764 - val_loss: 0.5113 - val_accuracy: 0.7930\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5258 - accuracy: 0.7764 - val_loss: 0.5105 - val_accuracy: 0.7930\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5260 - accuracy: 0.7764 - val_loss: 0.5123 - val_accuracy: 0.7930\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5340 - accuracy: 0.7764 - val_loss: 0.5136 - val_accuracy: 0.7930\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5284 - accuracy: 0.7764 - val_loss: 0.5119 - val_accuracy: 0.7930\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5262 - accuracy: 0.7764 - val_loss: 0.5102 - val_accuracy: 0.7930\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5249 - accuracy: 0.7764 - val_loss: 0.5129 - val_accuracy: 0.7930\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5289 - accuracy: 0.7764 - val_loss: 0.5084 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.7930\n",
            "Epoch 1/50\n",
            "32/32 [==============================] - 3s 21ms/step - loss: 0.5928 - accuracy: 0.7236 - val_loss: 0.5265 - val_accuracy: 0.7930\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5302 - accuracy: 0.7734 - val_loss: 0.5136 - val_accuracy: 0.7930\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5670 - accuracy: 0.7773 - val_loss: 0.5183 - val_accuracy: 0.7930\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5550 - accuracy: 0.7734 - val_loss: 0.5230 - val_accuracy: 0.7930\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5487 - accuracy: 0.7764 - val_loss: 0.5248 - val_accuracy: 0.7930\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5516 - accuracy: 0.7764 - val_loss: 0.5263 - val_accuracy: 0.7930\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5466 - accuracy: 0.7754 - val_loss: 0.5335 - val_accuracy: 0.7930\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5513 - accuracy: 0.7754 - val_loss: 0.5316 - val_accuracy: 0.7930\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5397 - accuracy: 0.7764 - val_loss: 0.5276 - val_accuracy: 0.7930\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5406 - accuracy: 0.7764 - val_loss: 0.5286 - val_accuracy: 0.7930\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5481 - accuracy: 0.7764 - val_loss: 0.5299 - val_accuracy: 0.7930\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5389 - accuracy: 0.7764 - val_loss: 0.5321 - val_accuracy: 0.7930\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5414 - accuracy: 0.7764 - val_loss: 0.5296 - val_accuracy: 0.7930\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5367 - accuracy: 0.7764 - val_loss: 0.5330 - val_accuracy: 0.7930\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5405 - accuracy: 0.7764 - val_loss: 0.5324 - val_accuracy: 0.7930\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5407 - accuracy: 0.7764 - val_loss: 0.5273 - val_accuracy: 0.7930\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5422 - accuracy: 0.7764 - val_loss: 0.5300 - val_accuracy: 0.7930\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5344 - accuracy: 0.7764 - val_loss: 0.5253 - val_accuracy: 0.7930\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5340 - accuracy: 0.7764 - val_loss: 0.5232 - val_accuracy: 0.7930\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5347 - accuracy: 0.7764 - val_loss: 0.5223 - val_accuracy: 0.7930\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5394 - accuracy: 0.7764 - val_loss: 0.5243 - val_accuracy: 0.7930\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5385 - accuracy: 0.7764 - val_loss: 0.5233 - val_accuracy: 0.7930\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5399 - accuracy: 0.7764 - val_loss: 0.5284 - val_accuracy: 0.7930\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5330 - accuracy: 0.7764 - val_loss: 0.5250 - val_accuracy: 0.7930\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5355 - accuracy: 0.7764 - val_loss: 0.5225 - val_accuracy: 0.7930\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5371 - accuracy: 0.7764 - val_loss: 0.5263 - val_accuracy: 0.7930\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5346 - accuracy: 0.7764 - val_loss: 0.5248 - val_accuracy: 0.7930\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5346 - accuracy: 0.7764 - val_loss: 0.5255 - val_accuracy: 0.7930\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5335 - accuracy: 0.7764 - val_loss: 0.5242 - val_accuracy: 0.7930\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5274 - accuracy: 0.7764 - val_loss: 0.5191 - val_accuracy: 0.7930\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5267 - accuracy: 0.7764 - val_loss: 0.5211 - val_accuracy: 0.7930\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5355 - accuracy: 0.7764 - val_loss: 0.5225 - val_accuracy: 0.7930\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5325 - accuracy: 0.7764 - val_loss: 0.5186 - val_accuracy: 0.7930\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5335 - accuracy: 0.7764 - val_loss: 0.5239 - val_accuracy: 0.7930\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5263 - accuracy: 0.7764 - val_loss: 0.5194 - val_accuracy: 0.7930\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5342 - accuracy: 0.7764 - val_loss: 0.5160 - val_accuracy: 0.7930\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5393 - accuracy: 0.7764 - val_loss: 0.5255 - val_accuracy: 0.7930\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5319 - accuracy: 0.7764 - val_loss: 0.5212 - val_accuracy: 0.7930\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5291 - accuracy: 0.7764 - val_loss: 0.5219 - val_accuracy: 0.7930\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5337 - accuracy: 0.7764 - val_loss: 0.5240 - val_accuracy: 0.7930\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5309 - accuracy: 0.7764 - val_loss: 0.5227 - val_accuracy: 0.7930\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5276 - accuracy: 0.7764 - val_loss: 0.5178 - val_accuracy: 0.7930\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5338 - accuracy: 0.7764 - val_loss: 0.5230 - val_accuracy: 0.7930\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5323 - accuracy: 0.7764 - val_loss: 0.5193 - val_accuracy: 0.7930\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5318 - accuracy: 0.7764 - val_loss: 0.5206 - val_accuracy: 0.7930\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5381 - accuracy: 0.7764 - val_loss: 0.5202 - val_accuracy: 0.7930\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5342 - accuracy: 0.7764 - val_loss: 0.5208 - val_accuracy: 0.7930\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5242 - accuracy: 0.7764 - val_loss: 0.5198 - val_accuracy: 0.7930\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5266 - accuracy: 0.7764 - val_loss: 0.5213 - val_accuracy: 0.7930\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5305 - accuracy: 0.7764 - val_loss: 0.5193 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5193 - accuracy: 0.7930\n",
            "Epoch 1/50\n",
            "32/32 [==============================] - 3s 22ms/step - loss: 0.5889 - accuracy: 0.7490 - val_loss: 0.5249 - val_accuracy: 0.7930\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5908 - accuracy: 0.7676 - val_loss: 0.5250 - val_accuracy: 0.7930\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5629 - accuracy: 0.7676 - val_loss: 0.5224 - val_accuracy: 0.7930\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5504 - accuracy: 0.7725 - val_loss: 0.5197 - val_accuracy: 0.7930\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5428 - accuracy: 0.7783 - val_loss: 0.5197 - val_accuracy: 0.7930\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5514 - accuracy: 0.7744 - val_loss: 0.5223 - val_accuracy: 0.7930\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5377 - accuracy: 0.7754 - val_loss: 0.5193 - val_accuracy: 0.7930\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5405 - accuracy: 0.7734 - val_loss: 0.5164 - val_accuracy: 0.7930\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5538 - accuracy: 0.7764 - val_loss: 0.5284 - val_accuracy: 0.7930\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5357 - accuracy: 0.7773 - val_loss: 0.5208 - val_accuracy: 0.7930\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5329 - accuracy: 0.7764 - val_loss: 0.5198 - val_accuracy: 0.7930\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5426 - accuracy: 0.7773 - val_loss: 0.5219 - val_accuracy: 0.7930\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5420 - accuracy: 0.7764 - val_loss: 0.5243 - val_accuracy: 0.7930\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5272 - accuracy: 0.7764 - val_loss: 0.5160 - val_accuracy: 0.7930\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5434 - accuracy: 0.7754 - val_loss: 0.5164 - val_accuracy: 0.7930\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5347 - accuracy: 0.7764 - val_loss: 0.5109 - val_accuracy: 0.7930\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5365 - accuracy: 0.7764 - val_loss: 0.5132 - val_accuracy: 0.7930\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5314 - accuracy: 0.7764 - val_loss: 0.5141 - val_accuracy: 0.7930\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5329 - accuracy: 0.7764 - val_loss: 0.5071 - val_accuracy: 0.7930\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5315 - accuracy: 0.7764 - val_loss: 0.5135 - val_accuracy: 0.7930\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5324 - accuracy: 0.7764 - val_loss: 0.5118 - val_accuracy: 0.7930\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5301 - accuracy: 0.7764 - val_loss: 0.5070 - val_accuracy: 0.7930\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5339 - accuracy: 0.7764 - val_loss: 0.5101 - val_accuracy: 0.7930\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5238 - accuracy: 0.7764 - val_loss: 0.5057 - val_accuracy: 0.7930\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5266 - accuracy: 0.7764 - val_loss: 0.5063 - val_accuracy: 0.7930\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5298 - accuracy: 0.7764 - val_loss: 0.5024 - val_accuracy: 0.7930\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5290 - accuracy: 0.7764 - val_loss: 0.5071 - val_accuracy: 0.7930\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5219 - accuracy: 0.7764 - val_loss: 0.5017 - val_accuracy: 0.7930\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5231 - accuracy: 0.7764 - val_loss: 0.5003 - val_accuracy: 0.7930\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5331 - accuracy: 0.7764 - val_loss: 0.5012 - val_accuracy: 0.7930\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5289 - accuracy: 0.7764 - val_loss: 0.5012 - val_accuracy: 0.7930\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5298 - accuracy: 0.7764 - val_loss: 0.5044 - val_accuracy: 0.7930\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5262 - accuracy: 0.7764 - val_loss: 0.5032 - val_accuracy: 0.7930\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5186 - accuracy: 0.7764 - val_loss: 0.5021 - val_accuracy: 0.7930\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5309 - accuracy: 0.7764 - val_loss: 0.5044 - val_accuracy: 0.7930\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5258 - accuracy: 0.7764 - val_loss: 0.5030 - val_accuracy: 0.7930\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5222 - accuracy: 0.7764 - val_loss: 0.5043 - val_accuracy: 0.7930\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5272 - accuracy: 0.7764 - val_loss: 0.5046 - val_accuracy: 0.7930\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5192 - accuracy: 0.7764 - val_loss: 0.4973 - val_accuracy: 0.7930\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5205 - accuracy: 0.7764 - val_loss: 0.5001 - val_accuracy: 0.7930\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5166 - accuracy: 0.7764 - val_loss: 0.4949 - val_accuracy: 0.7930\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5118 - accuracy: 0.7764 - val_loss: 0.4922 - val_accuracy: 0.7930\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5255 - accuracy: 0.7764 - val_loss: 0.5013 - val_accuracy: 0.7930\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5190 - accuracy: 0.7764 - val_loss: 0.4968 - val_accuracy: 0.7930\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5184 - accuracy: 0.7764 - val_loss: 0.4996 - val_accuracy: 0.7930\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5183 - accuracy: 0.7764 - val_loss: 0.4951 - val_accuracy: 0.7930\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5229 - accuracy: 0.7764 - val_loss: 0.4970 - val_accuracy: 0.7930\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5173 - accuracy: 0.7764 - val_loss: 0.4943 - val_accuracy: 0.7930\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5089 - accuracy: 0.7754 - val_loss: 0.4916 - val_accuracy: 0.7930\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5227 - accuracy: 0.7764 - val_loss: 0.5000 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.7930\n",
            "Epoch 1/50\n",
            "32/32 [==============================] - 3s 21ms/step - loss: 0.6364 - accuracy: 0.6904 - val_loss: 0.5179 - val_accuracy: 0.7930\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5651 - accuracy: 0.7656 - val_loss: 0.5203 - val_accuracy: 0.7930\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5655 - accuracy: 0.7725 - val_loss: 0.5198 - val_accuracy: 0.7930\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5628 - accuracy: 0.7734 - val_loss: 0.5249 - val_accuracy: 0.7930\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5509 - accuracy: 0.7754 - val_loss: 0.5207 - val_accuracy: 0.7930\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5358 - accuracy: 0.7744 - val_loss: 0.5177 - val_accuracy: 0.7930\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5579 - accuracy: 0.7754 - val_loss: 0.5291 - val_accuracy: 0.7930\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5431 - accuracy: 0.7773 - val_loss: 0.5233 - val_accuracy: 0.7930\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5414 - accuracy: 0.7764 - val_loss: 0.5264 - val_accuracy: 0.7930\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5473 - accuracy: 0.7764 - val_loss: 0.5244 - val_accuracy: 0.7930\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5411 - accuracy: 0.7764 - val_loss: 0.5232 - val_accuracy: 0.7930\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5380 - accuracy: 0.7764 - val_loss: 0.5252 - val_accuracy: 0.7930\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5404 - accuracy: 0.7764 - val_loss: 0.5242 - val_accuracy: 0.7930\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5415 - accuracy: 0.7764 - val_loss: 0.5227 - val_accuracy: 0.7930\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5432 - accuracy: 0.7764 - val_loss: 0.5246 - val_accuracy: 0.7930\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5425 - accuracy: 0.7764 - val_loss: 0.5231 - val_accuracy: 0.7930\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5387 - accuracy: 0.7764 - val_loss: 0.5235 - val_accuracy: 0.7930\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5354 - accuracy: 0.7764 - val_loss: 0.5234 - val_accuracy: 0.7930\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5380 - accuracy: 0.7764 - val_loss: 0.5224 - val_accuracy: 0.7930\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5302 - accuracy: 0.7764 - val_loss: 0.5194 - val_accuracy: 0.7930\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5380 - accuracy: 0.7764 - val_loss: 0.5207 - val_accuracy: 0.7930\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5311 - accuracy: 0.7764 - val_loss: 0.5181 - val_accuracy: 0.7930\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5412 - accuracy: 0.7764 - val_loss: 0.5188 - val_accuracy: 0.7930\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5242 - accuracy: 0.7764 - val_loss: 0.5179 - val_accuracy: 0.7930\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5297 - accuracy: 0.7764 - val_loss: 0.5175 - val_accuracy: 0.7930\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5294 - accuracy: 0.7764 - val_loss: 0.5144 - val_accuracy: 0.7930\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5349 - accuracy: 0.7764 - val_loss: 0.5176 - val_accuracy: 0.7930\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5317 - accuracy: 0.7764 - val_loss: 0.5169 - val_accuracy: 0.7930\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5310 - accuracy: 0.7764 - val_loss: 0.5210 - val_accuracy: 0.7930\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5277 - accuracy: 0.7764 - val_loss: 0.5140 - val_accuracy: 0.7930\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5304 - accuracy: 0.7764 - val_loss: 0.5147 - val_accuracy: 0.7930\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5285 - accuracy: 0.7764 - val_loss: 0.5183 - val_accuracy: 0.7930\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5267 - accuracy: 0.7764 - val_loss: 0.5074 - val_accuracy: 0.7930\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5238 - accuracy: 0.7764 - val_loss: 0.5149 - val_accuracy: 0.7930\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5255 - accuracy: 0.7764 - val_loss: 0.5056 - val_accuracy: 0.7930\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5227 - accuracy: 0.7764 - val_loss: 0.5107 - val_accuracy: 0.7930\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5274 - accuracy: 0.7764 - val_loss: 0.5140 - val_accuracy: 0.7930\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5209 - accuracy: 0.7764 - val_loss: 0.5057 - val_accuracy: 0.7930\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5237 - accuracy: 0.7764 - val_loss: 0.5041 - val_accuracy: 0.7930\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5216 - accuracy: 0.7764 - val_loss: 0.5055 - val_accuracy: 0.7930\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5222 - accuracy: 0.7764 - val_loss: 0.5035 - val_accuracy: 0.7930\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5288 - accuracy: 0.7764 - val_loss: 0.5084 - val_accuracy: 0.7930\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5266 - accuracy: 0.7764 - val_loss: 0.5056 - val_accuracy: 0.7930\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5140 - accuracy: 0.7764 - val_loss: 0.5054 - val_accuracy: 0.7930\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5218 - accuracy: 0.7764 - val_loss: 0.5074 - val_accuracy: 0.7930\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5176 - accuracy: 0.7764 - val_loss: 0.5035 - val_accuracy: 0.7930\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5173 - accuracy: 0.7764 - val_loss: 0.5064 - val_accuracy: 0.7930\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5170 - accuracy: 0.7764 - val_loss: 0.5008 - val_accuracy: 0.7930\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5183 - accuracy: 0.7764 - val_loss: 0.5045 - val_accuracy: 0.7930\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5191 - accuracy: 0.7764 - val_loss: 0.5053 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7930\n",
            "Epoch 1/50\n",
            "32/32 [==============================] - 3s 20ms/step - loss: 0.6053 - accuracy: 0.6855 - val_loss: 0.5119 - val_accuracy: 0.7930\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5675 - accuracy: 0.7695 - val_loss: 0.5097 - val_accuracy: 0.7930\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5487 - accuracy: 0.7754 - val_loss: 0.5084 - val_accuracy: 0.7930\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5471 - accuracy: 0.7734 - val_loss: 0.5122 - val_accuracy: 0.7930\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5610 - accuracy: 0.7725 - val_loss: 0.5118 - val_accuracy: 0.7930\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5611 - accuracy: 0.7764 - val_loss: 0.5146 - val_accuracy: 0.7930\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5415 - accuracy: 0.7754 - val_loss: 0.5095 - val_accuracy: 0.7930\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5464 - accuracy: 0.7764 - val_loss: 0.5116 - val_accuracy: 0.7930\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5507 - accuracy: 0.7744 - val_loss: 0.5165 - val_accuracy: 0.7930\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5414 - accuracy: 0.7764 - val_loss: 0.5137 - val_accuracy: 0.7930\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5406 - accuracy: 0.7764 - val_loss: 0.5163 - val_accuracy: 0.7930\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5387 - accuracy: 0.7764 - val_loss: 0.5123 - val_accuracy: 0.7930\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5314 - accuracy: 0.7764 - val_loss: 0.5101 - val_accuracy: 0.7930\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5357 - accuracy: 0.7764 - val_loss: 0.5117 - val_accuracy: 0.7930\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5442 - accuracy: 0.7764 - val_loss: 0.5106 - val_accuracy: 0.7930\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5318 - accuracy: 0.7764 - val_loss: 0.5126 - val_accuracy: 0.7930\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5341 - accuracy: 0.7764 - val_loss: 0.5094 - val_accuracy: 0.7930\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5400 - accuracy: 0.7764 - val_loss: 0.5134 - val_accuracy: 0.7930\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5282 - accuracy: 0.7764 - val_loss: 0.5111 - val_accuracy: 0.7930\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5375 - accuracy: 0.7764 - val_loss: 0.5106 - val_accuracy: 0.7930\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5401 - accuracy: 0.7764 - val_loss: 0.5113 - val_accuracy: 0.7930\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5352 - accuracy: 0.7764 - val_loss: 0.5131 - val_accuracy: 0.7930\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5278 - accuracy: 0.7764 - val_loss: 0.5114 - val_accuracy: 0.7930\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5300 - accuracy: 0.7764 - val_loss: 0.5115 - val_accuracy: 0.7930\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5301 - accuracy: 0.7764 - val_loss: 0.5107 - val_accuracy: 0.7930\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5306 - accuracy: 0.7764 - val_loss: 0.5110 - val_accuracy: 0.7930\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5304 - accuracy: 0.7764 - val_loss: 0.5099 - val_accuracy: 0.7930\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5331 - accuracy: 0.7764 - val_loss: 0.5111 - val_accuracy: 0.7930\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5243 - accuracy: 0.7764 - val_loss: 0.5102 - val_accuracy: 0.7930\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5303 - accuracy: 0.7764 - val_loss: 0.5123 - val_accuracy: 0.7930\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5293 - accuracy: 0.7764 - val_loss: 0.5142 - val_accuracy: 0.7930\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5321 - accuracy: 0.7764 - val_loss: 0.5108 - val_accuracy: 0.7930\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5286 - accuracy: 0.7764 - val_loss: 0.5132 - val_accuracy: 0.7930\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5340 - accuracy: 0.7764 - val_loss: 0.5117 - val_accuracy: 0.7930\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5285 - accuracy: 0.7764 - val_loss: 0.5119 - val_accuracy: 0.7930\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5295 - accuracy: 0.7764 - val_loss: 0.5120 - val_accuracy: 0.7930\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5322 - accuracy: 0.7764 - val_loss: 0.5109 - val_accuracy: 0.7930\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5305 - accuracy: 0.7764 - val_loss: 0.5144 - val_accuracy: 0.7930\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5324 - accuracy: 0.7764 - val_loss: 0.5115 - val_accuracy: 0.7930\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5265 - accuracy: 0.7764 - val_loss: 0.5104 - val_accuracy: 0.7930\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5286 - accuracy: 0.7764 - val_loss: 0.5126 - val_accuracy: 0.7930\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5353 - accuracy: 0.7764 - val_loss: 0.5110 - val_accuracy: 0.7930\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5326 - accuracy: 0.7764 - val_loss: 0.5115 - val_accuracy: 0.7930\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5249 - accuracy: 0.7764 - val_loss: 0.5115 - val_accuracy: 0.7930\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5256 - accuracy: 0.7764 - val_loss: 0.5086 - val_accuracy: 0.7930\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5314 - accuracy: 0.7764 - val_loss: 0.5107 - val_accuracy: 0.7930\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5325 - accuracy: 0.7764 - val_loss: 0.5112 - val_accuracy: 0.7930\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5247 - accuracy: 0.7764 - val_loss: 0.5091 - val_accuracy: 0.7930\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5302 - accuracy: 0.7764 - val_loss: 0.5128 - val_accuracy: 0.7930\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5262 - accuracy: 0.7764 - val_loss: 0.5117 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5117 - accuracy: 0.7930\n",
            "Epoch 1/50\n",
            "32/32 [==============================] - 4s 32ms/step - loss: 0.5941 - accuracy: 0.7383 - val_loss: 0.5250 - val_accuracy: 0.7930\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5677 - accuracy: 0.7744 - val_loss: 0.5212 - val_accuracy: 0.7930\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5644 - accuracy: 0.7764 - val_loss: 0.5250 - val_accuracy: 0.7930\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5504 - accuracy: 0.7725 - val_loss: 0.5268 - val_accuracy: 0.7930\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5445 - accuracy: 0.7764 - val_loss: 0.5256 - val_accuracy: 0.7930\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5402 - accuracy: 0.7773 - val_loss: 0.5213 - val_accuracy: 0.7930\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5527 - accuracy: 0.7744 - val_loss: 0.5262 - val_accuracy: 0.7930\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5517 - accuracy: 0.7773 - val_loss: 0.5273 - val_accuracy: 0.7930\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5440 - accuracy: 0.7764 - val_loss: 0.5231 - val_accuracy: 0.7930\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5361 - accuracy: 0.7783 - val_loss: 0.5237 - val_accuracy: 0.7930\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5451 - accuracy: 0.7764 - val_loss: 0.5274 - val_accuracy: 0.7930\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5417 - accuracy: 0.7764 - val_loss: 0.5291 - val_accuracy: 0.7930\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5375 - accuracy: 0.7764 - val_loss: 0.5265 - val_accuracy: 0.7930\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5304 - accuracy: 0.7764 - val_loss: 0.5273 - val_accuracy: 0.7930\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5310 - accuracy: 0.7764 - val_loss: 0.5239 - val_accuracy: 0.7930\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5415 - accuracy: 0.7764 - val_loss: 0.5271 - val_accuracy: 0.7930\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5399 - accuracy: 0.7764 - val_loss: 0.5256 - val_accuracy: 0.7930\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5377 - accuracy: 0.7764 - val_loss: 0.5280 - val_accuracy: 0.7930\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5338 - accuracy: 0.7764 - val_loss: 0.5257 - val_accuracy: 0.7930\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5414 - accuracy: 0.7764 - val_loss: 0.5260 - val_accuracy: 0.7930\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5385 - accuracy: 0.7764 - val_loss: 0.5226 - val_accuracy: 0.7930\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5447 - accuracy: 0.7764 - val_loss: 0.5247 - val_accuracy: 0.7930\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5400 - accuracy: 0.7764 - val_loss: 0.5270 - val_accuracy: 0.7930\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5349 - accuracy: 0.7764 - val_loss: 0.5281 - val_accuracy: 0.7930\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5269 - accuracy: 0.7764 - val_loss: 0.5242 - val_accuracy: 0.7930\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5299 - accuracy: 0.7764 - val_loss: 0.5280 - val_accuracy: 0.7930\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5296 - accuracy: 0.7764 - val_loss: 0.5239 - val_accuracy: 0.7930\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5271 - accuracy: 0.7764 - val_loss: 0.5236 - val_accuracy: 0.7930\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5357 - accuracy: 0.7764 - val_loss: 0.5221 - val_accuracy: 0.7930\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5339 - accuracy: 0.7764 - val_loss: 0.5249 - val_accuracy: 0.7930\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5319 - accuracy: 0.7764 - val_loss: 0.5280 - val_accuracy: 0.7930\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5331 - accuracy: 0.7764 - val_loss: 0.5246 - val_accuracy: 0.7930\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5303 - accuracy: 0.7764 - val_loss: 0.5230 - val_accuracy: 0.7930\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5350 - accuracy: 0.7764 - val_loss: 0.5251 - val_accuracy: 0.7930\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5363 - accuracy: 0.7764 - val_loss: 0.5238 - val_accuracy: 0.7930\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5328 - accuracy: 0.7764 - val_loss: 0.5238 - val_accuracy: 0.7930\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5333 - accuracy: 0.7764 - val_loss: 0.5219 - val_accuracy: 0.7930\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5245 - accuracy: 0.7764 - val_loss: 0.5216 - val_accuracy: 0.7930\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5352 - accuracy: 0.7764 - val_loss: 0.5232 - val_accuracy: 0.7930\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5337 - accuracy: 0.7764 - val_loss: 0.5249 - val_accuracy: 0.7930\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5351 - accuracy: 0.7764 - val_loss: 0.5228 - val_accuracy: 0.7930\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5323 - accuracy: 0.7764 - val_loss: 0.5225 - val_accuracy: 0.7930\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5315 - accuracy: 0.7764 - val_loss: 0.5243 - val_accuracy: 0.7930\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5321 - accuracy: 0.7764 - val_loss: 0.5241 - val_accuracy: 0.7930\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5363 - accuracy: 0.7764 - val_loss: 0.5212 - val_accuracy: 0.7930\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5345 - accuracy: 0.7764 - val_loss: 0.5230 - val_accuracy: 0.7930\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5301 - accuracy: 0.7764 - val_loss: 0.5198 - val_accuracy: 0.7930\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5289 - accuracy: 0.7764 - val_loss: 0.5203 - val_accuracy: 0.7930\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5309 - accuracy: 0.7764 - val_loss: 0.5203 - val_accuracy: 0.7930\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5361 - accuracy: 0.7764 - val_loss: 0.5199 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5199 - accuracy: 0.7930\n",
            "Epoch 1/50\n",
            "32/32 [==============================] - 3s 30ms/step - loss: 0.5939 - accuracy: 0.7197 - val_loss: 0.5182 - val_accuracy: 0.7930\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5697 - accuracy: 0.7744 - val_loss: 0.5178 - val_accuracy: 0.7930\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5613 - accuracy: 0.7705 - val_loss: 0.5172 - val_accuracy: 0.7930\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5434 - accuracy: 0.7695 - val_loss: 0.5190 - val_accuracy: 0.7930\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5595 - accuracy: 0.7754 - val_loss: 0.5181 - val_accuracy: 0.7930\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5490 - accuracy: 0.7725 - val_loss: 0.5236 - val_accuracy: 0.7930\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5412 - accuracy: 0.7754 - val_loss: 0.5155 - val_accuracy: 0.7930\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5339 - accuracy: 0.7764 - val_loss: 0.5152 - val_accuracy: 0.7930\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5338 - accuracy: 0.7754 - val_loss: 0.5149 - val_accuracy: 0.7930\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5367 - accuracy: 0.7764 - val_loss: 0.5114 - val_accuracy: 0.7930\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5420 - accuracy: 0.7764 - val_loss: 0.5130 - val_accuracy: 0.7930\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5353 - accuracy: 0.7764 - val_loss: 0.5123 - val_accuracy: 0.7930\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5292 - accuracy: 0.7754 - val_loss: 0.5109 - val_accuracy: 0.7930\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5285 - accuracy: 0.7764 - val_loss: 0.5119 - val_accuracy: 0.7930\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5319 - accuracy: 0.7764 - val_loss: 0.5098 - val_accuracy: 0.7930\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5351 - accuracy: 0.7764 - val_loss: 0.5130 - val_accuracy: 0.7930\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5318 - accuracy: 0.7764 - val_loss: 0.5101 - val_accuracy: 0.7930\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5233 - accuracy: 0.7764 - val_loss: 0.5071 - val_accuracy: 0.7930\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5218 - accuracy: 0.7764 - val_loss: 0.5061 - val_accuracy: 0.7930\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5232 - accuracy: 0.7764 - val_loss: 0.5079 - val_accuracy: 0.7930\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5313 - accuracy: 0.7764 - val_loss: 0.5098 - val_accuracy: 0.7930\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5202 - accuracy: 0.7764 - val_loss: 0.5059 - val_accuracy: 0.7930\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5243 - accuracy: 0.7764 - val_loss: 0.5056 - val_accuracy: 0.7930\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5296 - accuracy: 0.7764 - val_loss: 0.5063 - val_accuracy: 0.7930\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5272 - accuracy: 0.7764 - val_loss: 0.5084 - val_accuracy: 0.7930\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5187 - accuracy: 0.7764 - val_loss: 0.5087 - val_accuracy: 0.7930\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5151 - accuracy: 0.7764 - val_loss: 0.5090 - val_accuracy: 0.7930\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5245 - accuracy: 0.7754 - val_loss: 0.5111 - val_accuracy: 0.7930\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5252 - accuracy: 0.7764 - val_loss: 0.5102 - val_accuracy: 0.7930\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5240 - accuracy: 0.7764 - val_loss: 0.5088 - val_accuracy: 0.7930\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5229 - accuracy: 0.7764 - val_loss: 0.5076 - val_accuracy: 0.7930\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5163 - accuracy: 0.7764 - val_loss: 0.5069 - val_accuracy: 0.7930\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5120 - accuracy: 0.7764 - val_loss: 0.5082 - val_accuracy: 0.7930\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5223 - accuracy: 0.7764 - val_loss: 0.5081 - val_accuracy: 0.7930\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5176 - accuracy: 0.7764 - val_loss: 0.5084 - val_accuracy: 0.7930\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5190 - accuracy: 0.7764 - val_loss: 0.5109 - val_accuracy: 0.7930\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5142 - accuracy: 0.7764 - val_loss: 0.5060 - val_accuracy: 0.7930\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5143 - accuracy: 0.7764 - val_loss: 0.5085 - val_accuracy: 0.7930\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5167 - accuracy: 0.7764 - val_loss: 0.5070 - val_accuracy: 0.7930\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5141 - accuracy: 0.7764 - val_loss: 0.5075 - val_accuracy: 0.7930\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5140 - accuracy: 0.7764 - val_loss: 0.5097 - val_accuracy: 0.7930\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5132 - accuracy: 0.7764 - val_loss: 0.5102 - val_accuracy: 0.7930\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5104 - accuracy: 0.7764 - val_loss: 0.5077 - val_accuracy: 0.7930\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5099 - accuracy: 0.7764 - val_loss: 0.5094 - val_accuracy: 0.7930\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5066 - accuracy: 0.7764 - val_loss: 0.5096 - val_accuracy: 0.7930\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5108 - accuracy: 0.7764 - val_loss: 0.5087 - val_accuracy: 0.7930\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5116 - accuracy: 0.7764 - val_loss: 0.5107 - val_accuracy: 0.7930\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5136 - accuracy: 0.7764 - val_loss: 0.5101 - val_accuracy: 0.7930\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5050 - accuracy: 0.7764 - val_loss: 0.5092 - val_accuracy: 0.7930\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5116 - accuracy: 0.7764 - val_loss: 0.5107 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5107 - accuracy: 0.7930\n",
            "Epoch 1/50\n",
            "32/32 [==============================] - 3s 21ms/step - loss: 0.6036 - accuracy: 0.7119 - val_loss: 0.5202 - val_accuracy: 0.7930\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5671 - accuracy: 0.7754 - val_loss: 0.5202 - val_accuracy: 0.7930\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5536 - accuracy: 0.7744 - val_loss: 0.5229 - val_accuracy: 0.7930\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5580 - accuracy: 0.7715 - val_loss: 0.5243 - val_accuracy: 0.7930\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5544 - accuracy: 0.7744 - val_loss: 0.5230 - val_accuracy: 0.7930\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5541 - accuracy: 0.7764 - val_loss: 0.5296 - val_accuracy: 0.7930\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5460 - accuracy: 0.7764 - val_loss: 0.5243 - val_accuracy: 0.7930\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5449 - accuracy: 0.7754 - val_loss: 0.5231 - val_accuracy: 0.7930\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5427 - accuracy: 0.7764 - val_loss: 0.5224 - val_accuracy: 0.7930\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5366 - accuracy: 0.7764 - val_loss: 0.5223 - val_accuracy: 0.7930\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5464 - accuracy: 0.7764 - val_loss: 0.5244 - val_accuracy: 0.7930\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.5301 - accuracy: 0.7764 - val_loss: 0.5269 - val_accuracy: 0.7930\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.5350 - accuracy: 0.7764 - val_loss: 0.5227 - val_accuracy: 0.7930\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5370 - accuracy: 0.7764 - val_loss: 0.5209 - val_accuracy: 0.7930\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5432 - accuracy: 0.7764 - val_loss: 0.5249 - val_accuracy: 0.7930\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.5294 - accuracy: 0.7764 - val_loss: 0.5232 - val_accuracy: 0.7930\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 0.5347 - accuracy: 0.7764 - val_loss: 0.5269 - val_accuracy: 0.7930\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.5272 - accuracy: 0.7764 - val_loss: 0.5207 - val_accuracy: 0.7930\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5289 - accuracy: 0.7764 - val_loss: 0.5180 - val_accuracy: 0.7930\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5249 - accuracy: 0.7764 - val_loss: 0.5207 - val_accuracy: 0.7930\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5285 - accuracy: 0.7764 - val_loss: 0.5201 - val_accuracy: 0.7930\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5274 - accuracy: 0.7764 - val_loss: 0.5222 - val_accuracy: 0.7930\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5241 - accuracy: 0.7764 - val_loss: 0.5186 - val_accuracy: 0.7930\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5268 - accuracy: 0.7764 - val_loss: 0.5186 - val_accuracy: 0.7930\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5235 - accuracy: 0.7764 - val_loss: 0.5175 - val_accuracy: 0.7930\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5192 - accuracy: 0.7764 - val_loss: 0.5169 - val_accuracy: 0.7930\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5128 - accuracy: 0.7764 - val_loss: 0.5146 - val_accuracy: 0.7930\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.5181 - accuracy: 0.7764 - val_loss: 0.5188 - val_accuracy: 0.7930\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5287 - accuracy: 0.7764 - val_loss: 0.5222 - val_accuracy: 0.7930\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5186 - accuracy: 0.7764 - val_loss: 0.5158 - val_accuracy: 0.7930\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5288 - accuracy: 0.7764 - val_loss: 0.5314 - val_accuracy: 0.7930\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5264 - accuracy: 0.7764 - val_loss: 0.5168 - val_accuracy: 0.7930\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5210 - accuracy: 0.7764 - val_loss: 0.5185 - val_accuracy: 0.7930\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5140 - accuracy: 0.7764 - val_loss: 0.5196 - val_accuracy: 0.7930\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5180 - accuracy: 0.7764 - val_loss: 0.5152 - val_accuracy: 0.7930\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5161 - accuracy: 0.7764 - val_loss: 0.5219 - val_accuracy: 0.7930\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5202 - accuracy: 0.7754 - val_loss: 0.5177 - val_accuracy: 0.7930\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5231 - accuracy: 0.7764 - val_loss: 0.5184 - val_accuracy: 0.7930\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5178 - accuracy: 0.7764 - val_loss: 0.5129 - val_accuracy: 0.7930\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5198 - accuracy: 0.7764 - val_loss: 0.5230 - val_accuracy: 0.7930\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5185 - accuracy: 0.7764 - val_loss: 0.5142 - val_accuracy: 0.7930\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5178 - accuracy: 0.7764 - val_loss: 0.5155 - val_accuracy: 0.7930\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5158 - accuracy: 0.7764 - val_loss: 0.5151 - val_accuracy: 0.7930\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5129 - accuracy: 0.7764 - val_loss: 0.5143 - val_accuracy: 0.7930\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5074 - accuracy: 0.7764 - val_loss: 0.5154 - val_accuracy: 0.7930\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5149 - accuracy: 0.7764 - val_loss: 0.5149 - val_accuracy: 0.7930\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5096 - accuracy: 0.7764 - val_loss: 0.5168 - val_accuracy: 0.7930\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5095 - accuracy: 0.7764 - val_loss: 0.5174 - val_accuracy: 0.7930\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5200 - accuracy: 0.7764 - val_loss: 0.5139 - val_accuracy: 0.7930\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5152 - accuracy: 0.7764 - val_loss: 0.5182 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5182 - accuracy: 0.7930\n",
            "Epoch 1/50\n",
            "32/32 [==============================] - 3s 22ms/step - loss: 0.6044 - accuracy: 0.7061 - val_loss: 0.5258 - val_accuracy: 0.7930\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5660 - accuracy: 0.7695 - val_loss: 0.5261 - val_accuracy: 0.7930\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5500 - accuracy: 0.7744 - val_loss: 0.5244 - val_accuracy: 0.7930\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5600 - accuracy: 0.7725 - val_loss: 0.5269 - val_accuracy: 0.7930\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5522 - accuracy: 0.7754 - val_loss: 0.5261 - val_accuracy: 0.7930\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5363 - accuracy: 0.7754 - val_loss: 0.5255 - val_accuracy: 0.7930\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5472 - accuracy: 0.7764 - val_loss: 0.5279 - val_accuracy: 0.7930\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5433 - accuracy: 0.7764 - val_loss: 0.5281 - val_accuracy: 0.7930\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5447 - accuracy: 0.7754 - val_loss: 0.5286 - val_accuracy: 0.7930\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5403 - accuracy: 0.7773 - val_loss: 0.5270 - val_accuracy: 0.7930\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5450 - accuracy: 0.7764 - val_loss: 0.5272 - val_accuracy: 0.7930\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5341 - accuracy: 0.7764 - val_loss: 0.5256 - val_accuracy: 0.7930\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5468 - accuracy: 0.7764 - val_loss: 0.5260 - val_accuracy: 0.7930\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5400 - accuracy: 0.7764 - val_loss: 0.5274 - val_accuracy: 0.7930\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5364 - accuracy: 0.7764 - val_loss: 0.5246 - val_accuracy: 0.7930\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5382 - accuracy: 0.7764 - val_loss: 0.5275 - val_accuracy: 0.7930\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5324 - accuracy: 0.7764 - val_loss: 0.5234 - val_accuracy: 0.7930\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5357 - accuracy: 0.7764 - val_loss: 0.5255 - val_accuracy: 0.7930\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5230 - accuracy: 0.7764 - val_loss: 0.5238 - val_accuracy: 0.7930\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5371 - accuracy: 0.7764 - val_loss: 0.5247 - val_accuracy: 0.7930\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5385 - accuracy: 0.7764 - val_loss: 0.5261 - val_accuracy: 0.7930\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5356 - accuracy: 0.7764 - val_loss: 0.5233 - val_accuracy: 0.7930\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5362 - accuracy: 0.7764 - val_loss: 0.5277 - val_accuracy: 0.7930\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5350 - accuracy: 0.7764 - val_loss: 0.5258 - val_accuracy: 0.7930\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5369 - accuracy: 0.7764 - val_loss: 0.5251 - val_accuracy: 0.7930\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5335 - accuracy: 0.7764 - val_loss: 0.5237 - val_accuracy: 0.7930\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5328 - accuracy: 0.7764 - val_loss: 0.5225 - val_accuracy: 0.7930\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5305 - accuracy: 0.7764 - val_loss: 0.5234 - val_accuracy: 0.7930\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5365 - accuracy: 0.7764 - val_loss: 0.5265 - val_accuracy: 0.7930\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5349 - accuracy: 0.7764 - val_loss: 0.5235 - val_accuracy: 0.7930\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5362 - accuracy: 0.7764 - val_loss: 0.5225 - val_accuracy: 0.7930\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5376 - accuracy: 0.7764 - val_loss: 0.5245 - val_accuracy: 0.7930\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5286 - accuracy: 0.7764 - val_loss: 0.5239 - val_accuracy: 0.7930\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5356 - accuracy: 0.7764 - val_loss: 0.5247 - val_accuracy: 0.7930\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5351 - accuracy: 0.7764 - val_loss: 0.5208 - val_accuracy: 0.7930\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5331 - accuracy: 0.7764 - val_loss: 0.5227 - val_accuracy: 0.7930\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5279 - accuracy: 0.7764 - val_loss: 0.5208 - val_accuracy: 0.7930\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5349 - accuracy: 0.7764 - val_loss: 0.5213 - val_accuracy: 0.7930\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5336 - accuracy: 0.7764 - val_loss: 0.5215 - val_accuracy: 0.7930\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5382 - accuracy: 0.7764 - val_loss: 0.5230 - val_accuracy: 0.7930\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5346 - accuracy: 0.7764 - val_loss: 0.5226 - val_accuracy: 0.7930\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5389 - accuracy: 0.7764 - val_loss: 0.5214 - val_accuracy: 0.7930\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5294 - accuracy: 0.7764 - val_loss: 0.5195 - val_accuracy: 0.7930\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5371 - accuracy: 0.7764 - val_loss: 0.5214 - val_accuracy: 0.7930\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5331 - accuracy: 0.7764 - val_loss: 0.5200 - val_accuracy: 0.7930\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5342 - accuracy: 0.7764 - val_loss: 0.5220 - val_accuracy: 0.7930\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5300 - accuracy: 0.7764 - val_loss: 0.5202 - val_accuracy: 0.7930\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5330 - accuracy: 0.7764 - val_loss: 0.5207 - val_accuracy: 0.7930\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5325 - accuracy: 0.7764 - val_loss: 0.5211 - val_accuracy: 0.7930\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5346 - accuracy: 0.7764 - val_loss: 0.5218 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5218 - accuracy: 0.7930\n",
            "Epoch 1/50\n",
            "32/32 [==============================] - 5s 27ms/step - loss: 0.5965 - accuracy: 0.7314 - val_loss: 0.5283 - val_accuracy: 0.7930\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5751 - accuracy: 0.7764 - val_loss: 0.5263 - val_accuracy: 0.7930\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5480 - accuracy: 0.7773 - val_loss: 0.5260 - val_accuracy: 0.7930\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5464 - accuracy: 0.7764 - val_loss: 0.5283 - val_accuracy: 0.7930\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5540 - accuracy: 0.7764 - val_loss: 0.5263 - val_accuracy: 0.7930\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5417 - accuracy: 0.7764 - val_loss: 0.5287 - val_accuracy: 0.7930\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5450 - accuracy: 0.7764 - val_loss: 0.5278 - val_accuracy: 0.7930\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5393 - accuracy: 0.7764 - val_loss: 0.5312 - val_accuracy: 0.7930\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5366 - accuracy: 0.7764 - val_loss: 0.5300 - val_accuracy: 0.7930\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5371 - accuracy: 0.7764 - val_loss: 0.5310 - val_accuracy: 0.7930\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5442 - accuracy: 0.7764 - val_loss: 0.5310 - val_accuracy: 0.7930\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5385 - accuracy: 0.7764 - val_loss: 0.5300 - val_accuracy: 0.7930\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5378 - accuracy: 0.7764 - val_loss: 0.5297 - val_accuracy: 0.7930\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5340 - accuracy: 0.7764 - val_loss: 0.5274 - val_accuracy: 0.7930\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5337 - accuracy: 0.7764 - val_loss: 0.5277 - val_accuracy: 0.7930\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5362 - accuracy: 0.7764 - val_loss: 0.5293 - val_accuracy: 0.7930\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5352 - accuracy: 0.7764 - val_loss: 0.5262 - val_accuracy: 0.7930\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5335 - accuracy: 0.7764 - val_loss: 0.5291 - val_accuracy: 0.7930\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5399 - accuracy: 0.7764 - val_loss: 0.5289 - val_accuracy: 0.7930\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5360 - accuracy: 0.7764 - val_loss: 0.5266 - val_accuracy: 0.7930\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5346 - accuracy: 0.7764 - val_loss: 0.5250 - val_accuracy: 0.7930\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5290 - accuracy: 0.7764 - val_loss: 0.5257 - val_accuracy: 0.7930\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5428 - accuracy: 0.7764 - val_loss: 0.5300 - val_accuracy: 0.7930\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5425 - accuracy: 0.7764 - val_loss: 0.5251 - val_accuracy: 0.7930\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5360 - accuracy: 0.7764 - val_loss: 0.5292 - val_accuracy: 0.7930\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5353 - accuracy: 0.7764 - val_loss: 0.5275 - val_accuracy: 0.7930\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5358 - accuracy: 0.7764 - val_loss: 0.5282 - val_accuracy: 0.7930\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5323 - accuracy: 0.7764 - val_loss: 0.5271 - val_accuracy: 0.7930\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5372 - accuracy: 0.7764 - val_loss: 0.5257 - val_accuracy: 0.7930\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5301 - accuracy: 0.7764 - val_loss: 0.5253 - val_accuracy: 0.7930\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5302 - accuracy: 0.7764 - val_loss: 0.5268 - val_accuracy: 0.7930\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5344 - accuracy: 0.7764 - val_loss: 0.5284 - val_accuracy: 0.7930\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5260 - accuracy: 0.7764 - val_loss: 0.5245 - val_accuracy: 0.7930\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5354 - accuracy: 0.7764 - val_loss: 0.5294 - val_accuracy: 0.7930\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5354 - accuracy: 0.7764 - val_loss: 0.5244 - val_accuracy: 0.7930\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5269 - accuracy: 0.7764 - val_loss: 0.5240 - val_accuracy: 0.7930\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5303 - accuracy: 0.7764 - val_loss: 0.5220 - val_accuracy: 0.7930\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5261 - accuracy: 0.7764 - val_loss: 0.5236 - val_accuracy: 0.7930\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5300 - accuracy: 0.7764 - val_loss: 0.5243 - val_accuracy: 0.7930\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5268 - accuracy: 0.7764 - val_loss: 0.5246 - val_accuracy: 0.7930\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5300 - accuracy: 0.7764 - val_loss: 0.5253 - val_accuracy: 0.7930\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5311 - accuracy: 0.7764 - val_loss: 0.5224 - val_accuracy: 0.7930\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5296 - accuracy: 0.7764 - val_loss: 0.5205 - val_accuracy: 0.7930\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5229 - accuracy: 0.7764 - val_loss: 0.5219 - val_accuracy: 0.7930\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5260 - accuracy: 0.7764 - val_loss: 0.5225 - val_accuracy: 0.7930\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5307 - accuracy: 0.7764 - val_loss: 0.5243 - val_accuracy: 0.7930\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5260 - accuracy: 0.7764 - val_loss: 0.5236 - val_accuracy: 0.7930\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5341 - accuracy: 0.7764 - val_loss: 0.5231 - val_accuracy: 0.7930\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5262 - accuracy: 0.7764 - val_loss: 0.5213 - val_accuracy: 0.7930\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5275 - accuracy: 0.7764 - val_loss: 0.5245 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5245 - accuracy: 0.7930\n",
            "        frontal   central  parietal  occipital\n",
            "theta  0.792969  0.792969  0.792969   0.792969\n",
            "alpha  0.792969  0.792969  0.792969   0.792969\n",
            "beta   0.792969  0.792969  0.792969   0.792969\n",
            "gamma  0.792969  0.792969  0.792969   0.792969\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oY9uqQzbv46q"
      },
      "outputs": [],
      "source": [
        "# print the confusion matrix which gives the highest accuracy\n",
        "print_conf(\"theta\",\"parietal\",\"arousal\",\"svm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHUBype4mFY6"
      },
      "outputs": [],
      "source": [
        "print_accuracy('valence', 'svm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bv3oLNIVGCSf"
      },
      "outputs": [],
      "source": [
        "print_conf(\"gamma\",\"central\",\"valence\",\"svm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IoKgtLNEpU-v"
      },
      "outputs": [],
      "source": [
        "print_accuracy('HAHV', 'ab')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BcqO8QBLHR7q"
      },
      "outputs": [],
      "source": [
        "print_conf(\"gamma\",\"occipital\",\"arousal\",\"ab\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1za3TrVphgH"
      },
      "outputs": [],
      "source": [
        "print_accuracy('valence', 'ab')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1DPjYGhArgcr"
      },
      "outputs": [],
      "source": [
        "print_accuracy('HAHV', 'xgb')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wYrfmtLwrmES"
      },
      "outputs": [],
      "source": [
        "print_accuracy('valence', 'xgb')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_wzHU40YhWY"
      },
      "outputs": [],
      "source": [
        "print_conf(\"beta\",\"central\",\"valence\",\"xgb\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3qH1vs2J5rC"
      },
      "outputs": [],
      "source": [
        "print_accuracy('HAHV', 'knn')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x84JhQCIKciv"
      },
      "outputs": [],
      "source": [
        "print_accuracy('LALV', 'knn')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7XXLSSWWl9kI"
      },
      "outputs": [],
      "source": [
        "print_accuracy('HALV', 'knn')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4WnM3ismDzw"
      },
      "outputs": [],
      "source": [
        "print_accuracy('LAHV', 'knn')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pXS8oiqJKknT"
      },
      "outputs": [],
      "source": [
        "print_accuracy('HAHV', 'dtree')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zPn1ljyNKtr4"
      },
      "outputs": [],
      "source": [
        "print_accuracy('LALV', 'dtree')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zS_EF8dRKyLm"
      },
      "outputs": [],
      "source": [
        "print_accuracy('HAHV', 'rf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "luDd1AY6mjqs"
      },
      "outputs": [],
      "source": [
        "print_accuracy('LAHV', 'rf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GNTGFHQOK14l"
      },
      "outputs": [],
      "source": [
        "print_accuracy('HALV', 'rf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RhGLn0G4_l8E"
      },
      "outputs": [],
      "source": [
        "print_accuracy('LALV', 'rf')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy('HAHV', 'cnn')"
      ],
      "metadata": {
        "id": "lkL0I6x7PY-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MkmagqFfK54a"
      },
      "outputs": [],
      "source": [
        "print_accuracy('HALV', 'cnn')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uV3gnYCKK-cA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02_ynnQ1LEoz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tuwCpDS1LHAx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tAvwS8OmOkX6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIwlFJ7nOyFX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QBw1c8r9O6s5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mBzYOJwO-Tc"
      },
      "outputs": [],
      "source": [
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_tYtr1vPEwA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yz0L94FJPKCx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPkBIcPtPTXf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "al5LA0spYBqU"
      },
      "outputs": [],
      "source": [
        "# print_conf(\"gamma\",\"frontal\",\"arousal\",\"cb\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LB1NnMQQcTD"
      },
      "outputs": [],
      "source": [
        "print_accuracy('HAHV', 'cb')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}